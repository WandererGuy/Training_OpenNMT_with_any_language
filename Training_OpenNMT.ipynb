{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# credit goes to manhtech264@gmail.com"
      ],
      "metadata": {
        "id": "zF7j7ipIttFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# this translate Ede-English using OpenNMT-py and Sentencepiece tokenizer"
      ],
      "metadata": {
        "id": "C7G6EYrJuy97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# installing sentencepiece tokenizer"
      ],
      "metadata": {
        "id": "SHmFon87rgJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "install like in https://github.com/google/sentencepiece"
      ],
      "metadata": {
        "id": "RKUzIWL7rknL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrfCljqZqhyY",
        "outputId": "6f40eb8c-f6b3-49ef-91b8-9eb8ae193088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 257 kB in 1s (262 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libbz2-dev libpkgconf3 libreadline-dev\n",
            "Use 'apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get update && apt-get install -y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y cmake build-essential pkg-config libgoogle-perftools-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6Js1Qh4q3IB",
        "outputId": "4054c018-6ee3-4ef0-fde8-e11a59bce110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "libgoogle-perftools-dev is already the newest version (2.9.1-0ubuntu3).\n",
            "pkg-config is already the newest version (0.29.2-1ubuntu3).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libbz2-dev libpkgconf3 libreadline-dev\n",
            "Use 'apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/google/sentencepiece.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSZn71HTrDtb",
        "outputId": "610337e9-7cde-4a01-9d03-47018898019a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'sentencepiece' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQT8ONZ7rH21",
        "outputId": "9a7e83f9-ab1c-4fbe-8bed-efec7e62a698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sentencepiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir build"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQjXYqabrK9T",
        "outputId": "bb502143-592a-48f2-c53d-e549e0cd0b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘build’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd build"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNV0DefXrNZp",
        "outputId": "3c33f348-f11b-4ef7-ae02-48d747356666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sentencepiece/build\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cmake .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTmLKaw3rQXz",
        "outputId": "08faae80-a121-4345-fc13-a9a505a85e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:15 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.10 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
            "  to tell CMake that the project requires at least <min> but has been updated\n",
            "  to work with policies introduced by <max> or earlier.\n",
            "\n",
            "\u001b[0m\n",
            "-- VERSION: 0.2.1\n",
            "-- Found TCMalloc: /usr/lib/x86_64-linux-gnu/libtcmalloc_minimal.so\n",
            "-- Configuring done (0.1s)\n",
            "-- Generating done (0.1s)\n",
            "-- Build files have been written to: /content/sentencepiece/build\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make -j $(nproc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo_65I6urX71",
        "outputId": "26836188-3fb6-4b1e-ac83-0a6232fb1d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 36%] Built target sentencepiece-static\n",
            "[ 71%] Built target sentencepiece\n",
            "[ 91%] Built target sentencepiece_train-static\n",
            "[ 91%] Built target sentencepiece_train\n",
            "[ 93%] Built target spm_encode\n",
            "[ 94%] Built target spm_decode\n",
            "[ 96%] Built target spm_normalize\n",
            "[ 98%] Built target spm_train\n",
            "[100%] Built target spm_export_vocab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab8bYyXmraol",
        "outputId": "126a5870-662c-4cc2-a973-1c5395c198be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 35%] Built target sentencepiece\n",
            "[ 45%] Built target sentencepiece_train\n",
            "[ 81%] Built target sentencepiece-static\n",
            "[ 91%] Built target sentencepiece_train-static\n",
            "[ 93%] Built target spm_encode\n",
            "[ 94%] Built target spm_decode\n",
            "[ 96%] Built target spm_normalize\n",
            "[ 98%] Built target spm_train\n",
            "[100%] Built target spm_export_vocab\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"\"\n",
            "-- Up-to-date: /usr/local/lib/pkgconfig/sentencepiece.pc\n",
            "-- Up-to-date: /usr/local/lib/libsentencepiece.so.0.0.0\n",
            "-- Up-to-date: /usr/local/lib/libsentencepiece.so.0\n",
            "-- Up-to-date: /usr/local/lib/libsentencepiece.so\n",
            "-- Up-to-date: /usr/local/lib/libsentencepiece_train.so.0.0.0\n",
            "-- Up-to-date: /usr/local/lib/libsentencepiece_train.so.0\n",
            "-- Up-to-date: /usr/local/lib/libsentencepiece_train.so\n",
            "-- Up-to-date: /usr/local/lib/libsentencepiece.a\n",
            "-- Up-to-date: /usr/local/lib/libsentencepiece_train.a\n",
            "-- Up-to-date: /usr/local/bin/spm_encode\n",
            "-- Up-to-date: /usr/local/bin/spm_decode\n",
            "-- Up-to-date: /usr/local/bin/spm_normalize\n",
            "-- Up-to-date: /usr/local/bin/spm_train\n",
            "-- Up-to-date: /usr/local/bin/spm_export_vocab\n",
            "-- Up-to-date: /usr/local/include/sentencepiece_trainer.h\n",
            "-- Up-to-date: /usr/local/include/sentencepiece_processor.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ldconfig -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CiFkf1PredT",
        "outputId": "2eb985e9-4c3f-4f63-fb13-2ae22c6c8768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/sbin/ldconfig.real: Path `/usr/local/cuda-12/targets/x86_64-linux/lib' given more than once\n",
            "(from /etc/ld.so.conf.d/988_cuda-12.conf:1 and /etc/ld.so.conf.d/000_cuda.conf:1)\n",
            "/sbin/ldconfig.real: Path `/usr/local/cuda-12.5/targets/x86_64-linux/lib' given more than once\n",
            "(from /etc/ld.so.conf.d/gds-12-5.conf:1 and /etc/ld.so.conf.d/000_cuda.conf:1)\n",
            "/sbin/ldconfig.real: Path `/usr/local/lib' given more than once\n",
            "(from /etc/ld.so.conf.d/libc.conf:2 and /etc/ld.so.conf.d/colab.conf:1)\n",
            "/sbin/ldconfig.real: Can't stat /usr/local/nvidia/lib: No such file or directory\n",
            "/sbin/ldconfig.real: Can't stat /usr/local/nvidia/lib64: No such file or directory\n",
            "/sbin/ldconfig.real: Can't stat /usr/local/lib/x86_64-linux-gnu: No such file or directory\n",
            "/sbin/ldconfig.real: Path `/usr/lib/x86_64-linux-gnu' given more than once\n",
            "(from /etc/ld.so.conf.d/x86_64-linux-gnu.conf:4 and /etc/ld.so.conf.d/x86_64-linux-gnu.conf:3)\n",
            "/sbin/ldconfig.real: Path `/usr/lib32' given more than once\n",
            "(from /etc/ld.so.conf.d/zz_i386-biarch-compat.conf:3 and /etc/ld.so.conf.d/zz_i386-biarch-compat.conf:2)\n",
            "/sbin/ldconfig.real: Path `/lib/x86_64-linux-gnu' given more than once\n",
            "(from <builtin>:0 and /etc/ld.so.conf.d/x86_64-linux-gnu.conf:3)\n",
            "/sbin/ldconfig.real: Path `/usr/lib/x86_64-linux-gnu' given more than once\n",
            "(from <builtin>:0 and /etc/ld.so.conf.d/x86_64-linux-gnu.conf:3)\n",
            "/sbin/ldconfig.real: Path `/usr/lib' given more than once\n",
            "(from <builtin>:0 and <builtin>:0)\n",
            "/usr/local/cuda/targets/x86_64-linux/lib: (from /etc/ld.so.conf.d/000_cuda.conf:1)\n",
            "\tlibcufft.so.11 -> libcufft.so.11.2.3.61\n",
            "\tlibcublasLt.so.12 -> libcublasLt.so.12.5.3.2\n",
            "\tlibnppig.so.12 -> libnppig.so.12.3.0.159\n",
            "\tlibnvrtc-builtins.so.12.5 -> libnvrtc-builtins.so.12.5.82\n",
            "\tlibnvrtc.so.12 -> libnvrtc.so.12.5.82\n",
            "\tlibnppicc.so.12 -> libnppicc.so.12.3.0.159\n",
            "\tlibnvJitLink.so.12 -> libnvJitLink.so.12.5.82\n",
            "\tlibcufile_rdma.so.1 -> libcufile_rdma.so.1.10.1\n",
            "\tlibcufile.so.0 -> libcufile.so.1.10.1\n",
            "\tlibcufftw.so.11 -> libcufftw.so.11.2.3.61\n",
            "\tlibcusparse.so.12 -> libcusparse.so.12.5.1.3\n",
            "\tlibnvblas.so.12 -> libnvblas.so.12.5.3.2\n",
            "\tlibnpps.so.12 -> libnpps.so.12.3.0.159\n",
            "\tlibnvToolsExt.so.1 -> libnvToolsExt.so.1.0.0\n",
            "\tlibnppidei.so.12 -> libnppidei.so.12.3.0.159\n",
            "\tlibnppim.so.12 -> libnppim.so.12.3.0.159\n",
            "\tlibcusolver.so.11 -> libcusolver.so.11.6.3.83\n",
            "\tlibnppisu.so.12 -> libnppisu.so.12.3.0.159\n",
            "\tlibnvjpeg.so.12 -> libnvjpeg.so.12.3.2.81\n",
            "\tlibnppial.so.12 -> libnppial.so.12.3.0.159\n",
            "\tlibnppif.so.12 -> libnppif.so.12.3.0.159\n",
            "\tlibnppist.so.12 -> libnppist.so.12.3.0.159\n",
            "\tlibcusolverMg.so.11 -> libcusolverMg.so.11.6.3.83\n",
            "\tlibnvfatbin.so.12 -> libnvfatbin.so.12.5.82\n",
            "\tlibcurand.so.10 -> libcurand.so.10.3.6.82\n",
            "\tlibOpenCL.so.1 -> libOpenCL.so.1.0.0\n",
            "\tlibnppc.so.12 -> libnppc.so.12.3.0.159\n",
            "\tlibcublas.so.12 -> libcublas.so.12.5.3.2\n",
            "\tlibnppitc.so.12 -> libnppitc.so.12.3.0.159\n",
            "\tlibnvperf_host.so -> libnvperf_host.so\n",
            "\tlibnvperf_target.so -> libnvperf_target.so\n",
            "\tlibcuinj64.so.12.5 -> libcuinj64.so.12.5.82\n",
            "\tlibpcsamplingutil.so -> libpcsamplingutil.so\n",
            "\tlibcheckpoint.so -> libcheckpoint.so\n",
            "\tlibaccinj64.so.12.5 -> libaccinj64.so.12.5.82\n",
            "\tlibcupti.so.12 -> libcupti.so.2024.2.1\n",
            "\tlibcudart.so.12 -> libcudart.so.12.5.82\n",
            "/usr/local/lib: (from /etc/ld.so.conf.d/colab.conf:1)\n",
            "\tlibjulia.so.1.10 -> libjulia.so.1.10.9\n",
            "\tlibmkl_vml_avx2.so.2 -> libmkl_vml_avx2.so.2\n",
            "\tlibmkl_scalapack_ilp64.so.2 -> libmkl_scalapack_ilp64.so.2\n",
            "\tlibmkl_mc3.so.2 -> libmkl_mc3.so.2\n",
            "\tlibmkl_intel_lp64.so.2 -> libmkl_intel_lp64.so.2\n",
            "\tlibmkl_vml_avx512.so.2 -> libmkl_vml_avx512.so.2\n",
            "\tlibmkl_rt.so.2 -> libmkl_rt.so.2\n",
            "\tlibmkl_gnu_thread.so.2 -> libmkl_gnu_thread.so.2\n",
            "\tlibmkl_def.so.2 -> libmkl_def.so.2\n",
            "\tlibmkl_vml_mc3.so.2 -> libmkl_vml_mc3.so.2\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "\tlibtbbbind_2_5.so.3 -> libtbbbind_2_5.so.3.15\n",
            "\tlibmkl_vml_cmpt.so.2 -> libmkl_vml_cmpt.so.2\n",
            "\tlibmkl_sequential.so.2 -> libmkl_sequential.so.2\n",
            "\tlibiompstubs5.so -> libiompstubs5.so\n",
            "\tlibmkl_scalapack_lp64.so.2 -> libmkl_scalapack_lp64.so.2\n",
            "\tlibmkl_tbb_thread.so.2 -> libmkl_tbb_thread.so.2\n",
            "\tlibmkl_intel_ilp64.so.2 -> libmkl_intel_ilp64.so.2\n",
            "\tlibomptarget.sycl.wrap.so -> libomptarget.sycl.wrap.so\n",
            "\tlibmkl_blacs_intelmpi_ilp64.so.2 -> libmkl_blacs_intelmpi_ilp64.so.2\n",
            "\tlibmkl_avx512.so.2 -> libmkl_avx512.so.2\n",
            "\tlibomptarget.rtl.unified_runtime.so -> libomptarget.rtl.unified_runtime.so\n",
            "\tlibiomp5.so -> libiomp5.so\n",
            "\tlibarcher.so -> libarcher.so\n",
            "\tlibomptarget.so -> libomptarget.so\n",
            "\tlibmkl_gf_ilp64.so.2 -> libmkl_gf_ilp64.so.2\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "\tlibtbb.so.12 -> libtbb.so.12.15\n",
            "\tlibsycl_ur_trace_collector.so -> libsycl_ur_trace_collector.so\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "\tlibtcm_debug.so.1 -> libtcm_debug.so.1.3.0\n",
            "\tlibmkl_gf_lp64.so.2 -> libmkl_gf_lp64.so.2\n",
            "\tlibmkl_cdft_core.so.2 -> libmkl_cdft_core.so.2\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "\tlibtbbmalloc.so.2 -> libtbbmalloc.so.2.15\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "\tlibur_adapter_opencl.so.0 -> libur_adapter_opencl.so.0.11.10\n",
            "\tlibomptarget.rtl.x86_64.so -> libomptarget.rtl.x86_64.so\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "\tlibtbbmalloc_proxy.so.2 -> libtbbmalloc_proxy.so.2.15\n",
            "\tlibmkl_blacs_openmpi_lp64.so.2 -> libmkl_blacs_openmpi_lp64.so.2\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "\tlibtbbbind.so.3 -> libtbbbind.so.3.15\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "\tlibur_loader.so.0 -> libur_loader.so.0.11.10\n",
            "\tlibmkl_blacs_openmpi_ilp64.so.2 -> libmkl_blacs_openmpi_ilp64.so.2\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "\tlibtbbbind_2_0.so.3 -> libtbbbind_2_0.so.3.15\n",
            "\tlibiomp5_db.so -> libiomp5_db.so\n",
            "\tlibmkl_blacs_intelmpi_lp64.so.2 -> libmkl_blacs_intelmpi_lp64.so.2\n",
            "\tlibmkl_vml_def.so.2 -> libmkl_vml_def.so.2\n",
            "\tlibomptarget.rtl.level0.so -> libomptarget.rtl.level0.so\n",
            "\tlibomptarget.rtl.opencl.so -> libomptarget.rtl.opencl.so\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "\tlibtcm.so.1 -> libtcm.so.1.3.0\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "\tlibumf.so.0 -> libumf.so.0.10.0\n",
            "\tlibmkl_avx2.so.2 -> libmkl_avx2.so.2\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "\tlibur_adapter_level_zero.so.0 -> libur_adapter_level_zero.so.0.11.10\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "\tlibhwloc.so.15 -> libhwloc.so.15.6.4\n",
            "\tlibmkl_intel_thread.so.2 -> libmkl_intel_thread.so.2\n",
            "\tlibmkl_core.so.2 -> libmkl_core.so.2\n",
            "\tlibsentencepiece_train.so.0 -> libsentencepiece_train.so.0.0.0\n",
            "\tlibsentencepiece.so.0 -> libsentencepiece.so.0.0.0\n",
            "/lib/x86_64-linux-gnu: (from /etc/ld.so.conf.d/x86_64-linux-gnu.conf:3)\n",
            "\tliblber-2.5.so.0 -> liblber-2.5.so.0.1.12\n",
            "\tlibldap-2.5.so.0 -> libldap-2.5.so.0.1.12\n",
            "\tlibnpth.so.0 -> libnpth.so.0.1.2\n",
            "\tlibassuan.so.0 -> libassuan.so.0.8.5\n",
            "\tlibhistory.so.8 -> libhistory.so.8.1\n",
            "\tlibsqlite3.so.0 -> libsqlite3.so.0.8.6\n",
            "\tlibreadline.so.8 -> libreadline.so.8.1\n",
            "\tlibksba.so.8 -> libksba.so.8.14.0\n",
            "\tlibsasl2.so.2 -> libsasl2.so.2.0.25\n",
            "\tlibnccl.so.2 -> libnccl.so.2.22.3\n",
            "\tlibcc1.so.0 -> libcc1.so.0.0.0\n",
            "\tlibctf-nobfd.so.0 -> libctf-nobfd.so.0.0.0\n",
            "\tlibperl.so.5.34 -> libperl.so.5.34.0\n",
            "\tlibtsan.so.0 -> libtsan.so.0.0.0\n",
            "\tlibgdbm_compat.so.4 -> libgdbm_compat.so.4.0.0\n",
            "\tlibgomp.so.1 -> libgomp.so.1.0.0\n",
            "\tlibquadmath.so.0 -> libquadmath.so.0.0.0\n",
            "\tlibctf.so.0 -> libctf.so.0.0.0\n",
            "\tlibubsan.so.1 -> libubsan.so.1.0.0\n",
            "\tlibatomic.so.1 -> libatomic.so.1.2.0\n",
            "\tlibgdbm.so.6 -> libgdbm.so.6.0.0\n",
            "\tlibmpfr.so.6 -> libmpfr.so.6.1.0\n",
            "\tlibopcodes-2.38-system.so -> libopcodes-2.38-system.so\n",
            "\tlibitm.so.1 -> libitm.so.1.0.0\n",
            "\tlibbfd-2.38-system.so -> libbfd-2.38-system.so\n",
            "\tlibisl.so.23 -> libisl.so.23.1.0\n",
            "\tliblsan.so.0 -> liblsan.so.0.0.0\n",
            "\tlibmpc.so.3 -> libmpc.so.3.2.1\n",
            "\tlibasan.so.6 -> libasan.so.6.0.0\n",
            "\tlibcudnn_cnn.so.9 -> libcudnn_cnn.so.9.2.1\n",
            "\tlibcudnn_heuristic.so.9 -> libcudnn_heuristic.so.9.2.1\n",
            "\tlibcudnn_ops.so.9 -> libcudnn_ops.so.9.2.1\n",
            "\tlibcudnn_adv.so.9 -> libcudnn_adv.so.9.2.1\n",
            "\tlibcudnn_engines_precompiled.so.9 -> libcudnn_engines_precompiled.so.9.2.1\n",
            "\tlibcudnn_graph.so.9 -> libcudnn_graph.so.9.2.1\n",
            "\tlibcudnn_engines_runtime_compiled.so.9 -> libcudnn_engines_runtime_compiled.so.9.2.1\n",
            "\tlibcudnn.so.9 -> libcudnn.so.9.2.1\n",
            "\tlibboost_fiber.so.1.74.0 -> libboost_fiber.so.1.74.0\n",
            "\tlibLLVM-14.so.1 -> libLLVM-14.so.1\n",
            "\tlibjsoncpp.so.25 -> libjsoncpp.so.1.9.5\n",
            "\tlibnspr4.so -> libnspr4.so\n",
            "\tlibmkl_vml_mc2.so -> libmkl_vml_mc2.so\n",
            "\tlibvtkkissfft-9.1.so.1 -> libvtkkissfft-9.1.so.9.1.0\n",
            "\tlibgccpp.so.1 -> libgccpp.so.1.4.1\n",
            "\tlibboost_chrono.so.1.74.0 -> libboost_chrono.so.1.74.0\n",
            "\tlibopencv_mcc.so.4.5d -> libopencv_mcc.so.4.5.4d\n",
            "\tlibboost_program_options.so.1.74.0 -> libboost_program_options.so.1.74.0\n",
            "\tlibicutest.so.70 -> libicutest.so.70.1\n",
            "\tlibgfapi.so.0 -> libgfapi.so.0.0.0\n",
            "\tlibmkl_vml_def.so -> libmkl_vml_def.so\n",
            "\tlibcolord.so.2 -> libcolord.so.2.0.5\n",
            "\tlibboost_container.so.1.74.0 -> libboost_container.so.1.74.0\n",
            "\tlibisccfg-9.18.30-0ubuntu0.22.04.2-Ubuntu.so -> libisccfg-9.18.30-0ubuntu0.22.04.2-Ubuntu.so\n",
            "\tlibscotch-6.1.so -> libscotch-6.1.3.so\n",
            "\tlibopencv_surface_matching.so.4.5d -> libopencv_surface_matching.so.4.5.4d\n",
            "\tlibvtkImagingStatistics-9.1.so.1 -> libvtkImagingStatistics-9.1.so.9.1.0\n",
            "\tlibavdevice.so.58 -> libavdevice.so.58.13.100\n",
            "\tlibboost_wave.so.1.74.0 -> libboost_wave.so.1.74.0\n",
            "\tlibdevmapper.so.1.02.1 -> libdevmapper.so.1.02.1\n",
            "\tlibmkl_intel_lp64.so -> libmkl_intel_lp64.so\n",
            "\tlibgdcmCommon.so.3.0 -> libgdcmCommon.so.3.0.10\n",
            "\tlibmkl_gf_lp64.so -> libmkl_gf_lp64.so\n",
            "\tlibvtkioss-9.1.so.1 -> libvtkioss-9.1.so.9.1.0\n",
            "\tlibXdamage.so.1 -> libXdamage.so.1.1.0\n",
            "\tlibopencv_barcode.so.4.5d -> libopencv_barcode.so.4.5.4d\n",
            "\tlibopencv_viz.so.4.5d -> libopencv_viz.so.4.5.4d\n",
            "\tlibnghttp2.so.14 -> libnghttp2.so.14.20.1\n",
            "\tlibnorm.so.1 -> libnorm.so.1\n",
            "\tlibvidstab.so.1.1 -> libvidstab.so.1.1\n",
            "\tlibboost_numpy310.so.1.74.0 -> libboost_numpy310.so.1.74.0\n",
            "\tlibvtklibharu-9.1.so.1 -> libvtklibharu-9.1.so.9.1.0\n",
            "\tlibvtkInteractionWidgets-9.1.so.1 -> libvtkInteractionWidgets-9.1.so.9.1.0\n",
            "\tliborc-test-0.4.so.0 -> liborc-test-0.4.so.0.32.0\n",
            "\tlibmpi_usempif08-gfortran.so.40 -> libmpi_usempif08-gfortran.so.40.30.0\n",
            "\tlibvtkFiltersImaging-9.1.so.1 -> libvtkFiltersImaging-9.1.so.9.1.0\n",
            "\tlibvtkRenderingUI-9.1.so.1 -> libvtkRenderingUI-9.1.so.9.1.0\n",
            "\tlibproj.so.25 -> libproj.so.25.9.1.1\n",
            "\tlibfribidi.so.0 -> libfribidi.so.0.4.0\n",
            "\tlibopus.so.0 -> libopus.so.0.8.0\n",
            "\tlibpcre2-posix.so.3 -> libpcre2-posix.so.3.0.1\n",
            "\tlibopencv_video.so.4.5d -> libopencv_video.so.4.5.4d\n",
            "\tlibcodec2.so.1.0 -> libcodec2.so.1.0\n",
            "\tlibXt.so.6 -> libXt.so.6.0.0\n",
            "\tlibaio.so.1 -> libaio.so.1.0.1\n",
            "\tlibvtkFiltersGeneric-9.1.so.1 -> libvtkFiltersGeneric-9.1.so.9.1.0\n",
            "\tlibcdio_cdda.so.2 -> libcdio_cdda.so.2.0.0\n",
            "\tlibboost_serialization.so.1.74.0 -> libboost_serialization.so.1.74.0\n",
            "\tlibxtables.so.12 -> libxtables.so.12.4.0\n",
            "\tlibrabbitmq.so.4 -> librabbitmq.so.4.4.0\n",
            "\tlibfreetype.so.6 -> libfreetype.so.6.18.1\n",
            "\tlibnuma.so.1 -> libnuma.so.1.0.0\n",
            "\tlibboost_unit_test_framework.so.1.74.0 -> libboost_unit_test_framework.so.1.74.0\n",
            "\tlibpcre32.so.3 -> libpcre32.so.3.13.3\n",
            "\tlibmpi_usempi_ignore_tkr-gfortran.so.40 -> libmpi_usempi_ignore_tkr-gfortran.so.40.30.0\n",
            "\tlibjpeg.so.8 -> libjpeg.so.8.2.2\n",
            "\tlibvtkFiltersParallelGeometry-9.1.so.1 -> libvtkFiltersParallelGeometry-9.1.so.9.1.0\n",
            "\tlibopencv_stereo.so.4.5d -> libopencv_stereo.so.4.5.4d\n",
            "\tlibvtkFiltersExtraction-9.1.so.1 -> libvtkFiltersExtraction-9.1.so.9.1.0\n",
            "\tlibcairo-script-interpreter.so.2 -> libcairo-script-interpreter.so.2.11600.0\n",
            "\tlibvtkloguru-9.1.so.1 -> libvtkloguru-9.1.so.9.1.0\n",
            "\tlibvtkInteractionImage-9.1.so.1 -> libvtkInteractionImage-9.1.so.9.1.0\n",
            "\tlibasound.so.2 -> libasound.so.2.0.0\n",
            "\tlibmnl.so.0 -> libmnl.so.0.2.0\n",
            "\tlibvtkImagingMath-9.1.so.1 -> libvtkImagingMath-9.1.so.9.1.0\n",
            "\tlibgio-2.0.so.0 -> libgio-2.0.so.0.7200.4\n",
            "\tlibthai.so.0 -> libthai.so.0.3.1\n",
            "\tlibopencv_wechat_qrcode.so.4.5d -> libopencv_wechat_qrcode.so.4.5.4d\n",
            "\tlibgstnet-1.0.so.0 -> libgstnet-1.0.so.0.2003.0\n",
            "\tlibopencv_highgui.so.4.5d -> libopencv_highgui.so.4.5.4d\n",
            "\tlibvtkFiltersParallel-9.1.so.1 -> libvtkFiltersParallel-9.1.so.9.1.0\n",
            "\tlibvtkPythonContext2D-9.1.so.1 -> libvtkPythonContext2D-9.1.so.9.1.0\n",
            "\tlibsmime3.so -> libsmime3.so\n",
            "\tlibusb-1.0.so.0 -> libusb-1.0.so.0.3.0\n",
            "\tlibopencv_face.so.4.5d -> libopencv_face.so.4.5.4d\n",
            "\tlibspatialite.so.7 -> libspatialite.so.7.1.2\n",
            "\tlibvtkIOParallel-9.1.so.1 -> libvtkIOParallel-9.1.so.9.1.0\n",
            "\tlibbs2b.so.0 -> libbs2b.so.0.0.0\n",
            "\tlibns-9.18.30-0ubuntu0.22.04.2-Ubuntu.so -> libns-9.18.30-0ubuntu0.22.04.2-Ubuntu.so\n",
            "\tlibcdio_paranoia.so.2 -> libcdio_paranoia.so.2.0.0\n",
            "\tlibvtkfmt-9.1.so.1 -> libvtkfmt-9.1.so.9.1.0\n",
            "\tlibvtkFiltersTexture-9.1.so.1 -> libvtkFiltersTexture-9.1.so.9.1.0\n",
            "\tlibopencv_features2d.so.4.5d -> libopencv_features2d.so.4.5.4d\n",
            "\tliblzo2.so.2 -> liblzo2.so.2.0.0\n",
            "\tlibvtkIOAsynchronous-9.1.so.1 -> libvtkIOAsynchronous-9.1.so.9.1.0\n",
            "\tlibzmq.so.5 -> libzmq.so.5.2.4\n",
            "\tlibboost_stacktrace_basic.so.1.74.0 -> libboost_stacktrace_basic.so.1.74.0\n",
            "\tlibtbbmalloc_proxy.so.2 -> libtbbmalloc_proxy.so.2.5\n",
            "\tlibmagic.so.1 -> libmagic.so.1.0.0\n",
            "\tlibflite_cmu_time_awb.so.1 -> libflite_cmu_time_awb.so.2.2\n",
            "\tlibfreexl.so.1 -> libfreexl.so.1.1.0\n",
            "\tlibvtkImagingGeneral-9.1.so.1 -> libvtkImagingGeneral-9.1.so.9.1.0\n",
            "\tlibcups.so.2 -> libcups.so.2\n",
            "\tlibxerces-c-3.2.so -> libxerces-c.so\n",
            "\tlibopencv_bioinspired.so.4.5d -> libopencv_bioinspired.so.4.5.4d\n",
            "\tlibtesseract.so.4 -> libtesseract.so.4.0.1\n",
            "\tlibvtkRenderingVolume-9.1.so.1 -> libvtkRenderingVolume-9.1.so.9.1.0\n",
            "\tlibvtkImagingMorphological-9.1.so.1 -> libvtkImagingMorphological-9.1.so.9.1.0\n",
            "\tlibopencv_photo.so.4.5d -> libopencv_photo.so.4.5.4d\n",
            "\tlibvtkRenderingImage-9.1.so.1 -> libvtkRenderingImage-9.1.so.9.1.0\n",
            "\tlibudunits2.so.0 -> libudunits2.so.0.1.0\n",
            "\tlibfuse.so.2 -> libfuse.so.2.9.9\n",
            "\tlibopencv_datasets.so.4.5d -> libopencv_datasets.so.4.5.4d\n",
            "\tlibaom.so.3 -> libaom.so.3.3.0\n",
            "\tlibsphinxbase.so.3 -> libsphinxbase.so.3.0.0\n",
            "\tlibbsd.so.0 -> libbsd.so.0.11.5\n",
            "\tlibchromaprint.so.1 -> libchromaprint.so.1.5.1\n",
            "\tlibboost_filesystem.so.1.74.0 -> libboost_filesystem.so.1.74.0\n",
            "\tlibhdf5_serial_hl.so.100 -> libhdf5_serial_hl.so.100.1.4\n",
            "\tlibgit2.so.1.1 -> libgit2.so.1.1.0\n",
            "\tlibflite_cmu_indic_lang.so.1 -> libflite_cmu_indic_lang.so.2.2\n",
            "\tlibsamplerate.so.0 -> libsamplerate.so.0.2.2\n",
            "\tlibmkl_mc.so -> libmkl_mc.so\n",
            "\tlibvtkIOParallelNetCDF-9.1.so.1 -> libvtkIOParallelNetCDF-9.1.so.9.1.0\n",
            "\tlibodbcinst.so.2 -> libodbcinst.so.2.0.0\n",
            "\tlibgtk-3.so.0 -> libgtk-3.so.0.2404.29\n",
            "\tlibhdf5_serial_fortran.so.102 -> libhdf5_serial_fortran.so.102.1.0\n",
            "\tlibmkl_mc3.so -> libmkl_mc3.so\n",
            "\tlibvtkRenderingOpenGL2-9.1.so.1 -> libvtkRenderingOpenGL2-9.1.so.9.1.0\n",
            "\tlibtheoraenc.so.1 -> libtheoraenc.so.1.1.2\n",
            "\tlibgstpbutils-1.0.so.0 -> libgstpbutils-1.0.so.0.2001.0\n",
            "\tlibXrender.so.1 -> libXrender.so.1.3.0\n",
            "\tlibtiffxx.so.5 -> libtiffxx.so.5.7.0\n",
            "\tlibvtkCommonComputationalGeometry-9.1.so.1 -> libvtkCommonComputationalGeometry-9.1.so.9.1.0\n",
            "\tlibboost_math_tr1l.so.1.74.0 -> libboost_math_tr1l.so.1.74.0\n",
            "\tlibgts-0.7.so.5 -> libgts-0.7.so.5.0.1\n",
            "\tlibopen-rte.so.40 -> libopen-rte.so.40.30.2\n",
            "\tlibvtkIOMPIParallel-9.1.so.1 -> libvtkIOMPIParallel-9.1.so.9.1.0\n",
            "\tlibvtkIOXMLParser-9.1.so.1 -> libvtkIOXMLParser-9.1.so.9.1.0\n",
            "\tlibnss3.so -> libnss3.so\n",
            "\tliblab_gamut.so.1 -> liblab_gamut.so.1.0.0\n",
            "\tlibgdcmjpeg8.so.3.0 -> libgdcmjpeg8.so.3.0.10\n",
            "\tlibglib-2.0.so.0 -> libglib-2.0.so.0.7200.4\n",
            "\tlibunwind-ptrace.so.0 -> libunwind-ptrace.so.0.0.0\n",
            "\tlibpangocairo-1.0.so.0 -> libpangocairo-1.0.so.0.5000.6\n",
            "\tlibmkl_sequential.so -> libmkl_sequential.so\n",
            "\tlibBlocksRuntime.so.0 -> libBlocksRuntime.so.0.0.0\n",
            "\tlibaec.so.0 -> libaec.so.0.0.12\n",
            "\tlibopencv_hdf.so.4.5d -> libopencv_hdf.so.4.5.4d\n",
            "\tlibcairo-gobject.so.2 -> libcairo-gobject.so.2.11600.0\n",
            "\tlibtcmalloc_minimal_debug.so.4 -> libtcmalloc_minimal_debug.so.4.5.9\n",
            "\tlibvtkIOAMR-9.1.so.1 -> libvtkIOAMR-9.1.so.9.1.0\n",
            "\tlibx264.so.163 -> libx264.so.163\n",
            "\tlibX11-xcb.so.1 -> libX11-xcb.so.1.0.0\n",
            "\tlibpulse-simple.so.0 -> libpulse-simple.so.0.1.1\n",
            "\tlibvtkIOExport-9.1.so.1 -> libvtkIOExport-9.1.so.9.1.0\n",
            "\tlibgvc.so.6 -> libgvc.so.6.0.0\n",
            "\tlibobjc.so.4 -> libobjc.so.4.0.0\n",
            "\tlibmca_common_ucx.so.40 -> libmca_common_ucx.so.40.30.1\n",
            "\tlibgstsdp-1.0.so.0 -> libgstsdp-1.0.so.0.2001.0\n",
            "\tlibopencv_optflow.so.4.5d -> libopencv_optflow.so.4.5.4d\n",
            "\tlibapparmor.so.1 -> libapparmor.so.1.8.2\n",
            "\tlibxcb-shape.so.0 -> libxcb-shape.so.0.0.0\n",
            "\tlibirs-9.18.30-0ubuntu0.22.04.2-Ubuntu.so -> libirs-9.18.30-0ubuntu0.22.04.2-Ubuntu.so\n",
            "\tlibboost_atomic.so.1.74.0 -> libboost_atomic.so.1.74.0\n",
            "\tlibgdcmDICT.so.3.0 -> libgdcmDICT.so.3.0.10\n",
            "\tlibkadm5srv_mit.so.12 -> libkadm5srv_mit.so.12.0\n",
            "\tlibvtkFiltersPoints-9.1.so.1 -> libvtkFiltersPoints-9.1.so.9.1.0\n",
            "\tlibrubberband.so.2 -> librubberband.so.2.1.5\n",
            "\tlibmpi_mpifh.so.40 -> libmpi_mpifh.so.40.30.0\n",
            "\tlibxml2.so.2 -> libxml2.so.2.9.13\n",
            "\tlibopencv_xobjdetect.so.4.5d -> libopencv_xobjdetect.so.4.5.4d\n",
            "\tlibvtkexodusII-9.1.so.1 -> libvtkexodusII-9.1.so.9.1.0\n",
            "\tlibssl3.so -> libssl3.so\n",
            "\tlibuchardet.so.0 -> libuchardet.so.0.0.7\n",
            "\tlibSDL2-2.0.so.0 -> libSDL2-2.0.so.0.18.2\n",
            "\tlibSM.so.6 -> libSM.so.6.0.1\n",
            "\tlibzvbi.so.0 -> libzvbi.so.0.13.2\n",
            "\tlibvtkIOExodus-9.1.so.1 -> libvtkIOExodus-9.1.so.9.1.0\n",
            "\tlibhttp_parser.so.2.9 -> libhttp_parser.so.2.9.4\n",
            "\tlibmp3lame.so.0 -> libmp3lame.so.0.0.0\n",
            "\tlibXfont2.so.2 -> libXfont2.so.2.0.0\n",
            "\tlibvtkpugixml-9.1.so.1 -> libvtkpugixml-9.1.so.9.1.0\n",
            "\tlibvtkRenderingLOD-9.1.so.1 -> libvtkRenderingLOD-9.1.so.9.1.0\n",
            "\tlibutempter.so.0 -> libutempter.so.1.2.1\n",
            "\tlibopencv_fuzzy.so.4.5d -> libopencv_fuzzy.so.4.5.4d\n",
            "\tlibogg.so.0 -> libogg.so.0.8.5\n",
            "\tlibflite_cmu_indic_lex.so.1 -> libflite_cmu_indic_lex.so.2.2\n",
            "\tlibopencv_img_hash.so.4.5d -> libopencv_img_hash.so.4.5.4d\n",
            "\tlibmca_common_monitoring.so.50 -> libmca_common_monitoring.so.50.20.0\n",
            "\tlibnl-route-3.so.200 -> libnl-route-3.so.200.26.0\n",
            "\tlibvtkCommonPython-9.1.so.1 -> libvtkCommonPython-9.1.so.9.1.0\n",
            "\tlibvtkRenderingContext2D-9.1.so.1 -> libvtkRenderingContext2D-9.1.so.9.1.0\n",
            "\tlibboost_date_time.so.1.74.0 -> libboost_date_time.so.1.74.0\n",
            "\tlibmkl_vml_avx512.so -> libmkl_vml_avx512.so\n",
            "\tlibopencv_structured_light.so.4.5d -> libopencv_structured_light.so.4.5.4d\n",
            "\tlibopencv_xphoto.so.4.5d -> libopencv_xphoto.so.4.5.4d\n",
            "\tlibdw.so.1 -> libdw-0.186.so\n",
            "\tlibkadm5clnt_mit.so.12 -> libkadm5clnt_mit.so.12.0\n",
            "\tlibkmlengine.so.1 -> libkmlengine.so.1.3.0\n",
            "\tlibvtkImagingSources-9.1.so.1 -> libvtkImagingSources-9.1.so.9.1.0\n",
            "\tlibvtkIOCityGML-9.1.so.1 -> libvtkIOCityGML-9.1.so.9.1.0\n",
            "\tlibvtkIOExportGL2PS-9.1.so.1 -> libvtkIOExportGL2PS-9.1.so.9.1.0\n",
            "\tlibvtkIOChemistry-9.1.so.1 -> libvtkIOChemistry-9.1.so.9.1.0\n",
            "\tlibopencv_hfs.so.4.5d -> libopencv_hfs.so.4.5.4d\n",
            "\tlibdrm.so.2 -> libdrm.so.2.4.0\n",
            "\tlibopencv_imgcodecs.so.4.5d -> libopencv_imgcodecs.so.4.5.4d\n",
            "\tlibpocketsphinx.so.3 -> libpocketsphinx.so.3.0.0\n",
            "\tlibvtkPythonInterpreter-9.1.so.1 -> libvtkPythonInterpreter-9.1.so.9.1.0\n",
            "\tlibboost_random.so.1.74.0 -> libboost_random.so.1.74.0\n",
            "\tlibwebpmux.so.3 -> libwebpmux.so.3.0.8\n",
            "\tlibboost_prg_exec_monitor.so.1.74.0 -> libboost_prg_exec_monitor.so.1.74.0\n",
            "\tlibopencv_tracking.so.4.5d -> libopencv_tracking.so.4.5.4d\n",
            "\tlibvtkInteractionStyle-9.1.so.1 -> libvtkInteractionStyle-9.1.so.9.1.0\n",
            "\tlibpackagekit-glib2.so.18 -> libpackagekit-glib2.so.18.1.3\n",
            "\tlibvtkFiltersSMP-9.1.so.1 -> libvtkFiltersSMP-9.1.so.9.1.0\n",
            "\tlibvorbisenc.so.2 -> libvorbisenc.so.2.0.12\n",
            "\tlibvtkIOMotionFX-9.1.so.1 -> libvtkIOMotionFX-9.1.so.9.1.0\n",
            "\tlibmpdec.so.3 -> libmpdec.so.2.5.1\n",
            "\tlibflite_cmu_us_awb.so.1 -> libflite_cmu_us_awb.so.2.2\n",
            "\tlibmkl_core.so -> libmkl_core.so\n",
            "\tlibopencv_videostab.so.4.5d -> libopencv_videostab.so.4.5.4d\n",
            "\tlibtiff.so.5 -> libtiff.so.5.7.0\n",
            "\tlibgvpr.so.2 -> libgvpr.so.2.0.0\n",
            "\tlibvtkFiltersVerdict-9.1.so.1 -> libvtkFiltersVerdict-9.1.so.9.1.0\n",
            "\tlibvtkRenderingVolumeOpenGL2-9.1.so.1 -> libvtkRenderingVolumeOpenGL2-9.1.so.9.1.0\n",
            "\tlibflite.so.1 -> libflite.so.2.2\n",
            "\tlibboost_math_tr1.so.1.74.0 -> libboost_math_tr1.so.1.74.0\n",
            "\tlibprotoc.so.23 -> libprotoc.so.23.0.4\n",
            "\tlibgsttag-1.0.so.0 -> libgsttag-1.0.so.0.2001.0\n",
            "\tlibarchive.so.13 -> libarchive.so.13.6.0\n",
            "\tlibgstreamer-1.0.so.0 -> libgstreamer-1.0.so.0.2003.0\n",
            "\tlibvorbis.so.0 -> libvorbis.so.0.4.9\n",
            "\tlibvtkCommonSystem-9.1.so.1 -> libvtkCommonSystem-9.1.so.9.1.0\n",
            "\tlibsocket++.so.1 -> libsocket++.so.1.0.2\n",
            "\tlibodbc.so.2 -> libodbc.so.2.0.0\n",
            "\tlibudfread.so.0 -> libudfread.so.0.1.0\n",
            "\tlibmca_common_sm.so.40 -> libmca_common_sm.so.40.30.0\n",
            "\tlibGLEW.so.2.2 -> libGLEW.so.2.2.0\n",
            "\tlibmkl_tbb_thread.so -> libmkl_tbb_thread.so\n",
            "\tlibopencv_stitching.so.4.5d -> libopencv_stitching.so.4.5.4d\n",
            "\tlibvtkRenderingVtkJS-9.1.so.1 -> libvtkRenderingVtkJS-9.1.so.9.1.0\n",
            "\tlibslang.so.2 -> libslang.so.2.3.2\n",
            "\tlibmpi_usempif08.so.40 -> libmpi_usempif08.so.40.30.0\n",
            "\tlibzimg.so.2 -> libzimg.so.2.0.0\n",
            "\tlibtcmalloc_and_profiler.so.4 -> libtcmalloc_and_profiler.so.4.6.4\n",
            "\tlibvtkIOXML-9.1.so.1 -> libvtkIOXML-9.1.so.9.1.0\n",
            "\tlibmlx4.so.1 -> libmlx4.so.1.0.39.0\n",
            "\tlibkmod.so.2 -> libkmod.so.2.3.7\n",
            "\tlibopencv_ccalib.so.4.5d -> libopencv_ccalib.so.4.5.4d\n",
            "\tlibvtkFiltersCore-9.1.so.1 -> libvtkFiltersCore-9.1.so.9.1.0\n",
            "\tlibavutil.so.56 -> libavutil.so.56.70.100\n",
            "\tlibxshmfence.so.1 -> libxshmfence.so.1.0.0\n",
            "\tlibdeflate.so.0 -> libdeflate.so.0\n",
            "\tlibsigsegv.so.2 -> libsigsegv.so.2.0.6\n",
            "\tlibmd.so.0 -> libmd.so.0.0.5\n",
            "\tlibXext.so.6 -> libXext.so.6.4.0\n",
            "\tlibvtkInfovisLayout-9.1.so.1 -> libvtkInfovisLayout-9.1.so.9.1.0\n",
            "\tlibva.so.2 -> libva.so.2.1400.0\n",
            "\tlibxcb-xfixes.so.0 -> libxcb-xfixes.so.0.0.0\n",
            "\tlibgraphene-1.0.so.0 -> libgraphene-1.0.so.0.1000.8\n",
            "\tlibelf.so.1 -> libelf-0.186.so\n",
            "\tlibflite_cmu_grapheme_lex.so.1 -> libflite_cmu_grapheme_lex.so.2.2\n",
            "\tlibwebp.so.7 -> libwebp.so.7.1.3\n",
            "\tlibopencv_core.so.4.5d -> libopencv_core.so.4.5.4d\n",
            "\tlibboost_locale.so.1.74.0 -> libboost_locale.so.1.74.0\n",
            "\tlibboost_mpi.so.1.74.0 -> libboost_mpi.so.1.74.0\n",
            "\tlibboost_system.so.1.74.0 -> libboost_system.so.1.74.0\n",
            "\tlibvtkIOSegY-9.1.so.1 -> libvtkIOSegY-9.1.so.9.1.0\n",
            "\tlibdconf.so.1 -> libdconf.so.1.0.0\n",
            "\tlibdaxctl.so.1 -> libdaxctl.so.1.6.0\n",
            "\tlibXpm.so.4 -> libXpm.so.4.11.0\n",
            "\tlibnssutil3.so -> libnssutil3.so\n",
            "\tliblapack_atlas.so.3 -> liblapack_atlas.so.3.10.3\n",
            "\tlibvtkIOGeometry-9.1.so.1 -> libvtkIOGeometry-9.1.so.9.1.0\n",
            "\tlibboost_context.so.1.74.0 -> libboost_context.so.1.74.0\n",
            "\tlibfido2.so.1 -> libfido2.so.1.10.0\n",
            "\tlibopencv_text.so.4.5d -> libopencv_text.so.4.5.4d\n",
            "\tlibmkl_avx512.so -> libmkl_avx512.so\n",
            "\tlibvtkCommonCore-9.1.so.1 -> libvtkCommonCore-9.1.so.9.1.0\n",
            "\tlibgfrpc.so.0 -> libgfrpc.so.0.0.1\n",
            "\tlibedit.so.2 -> libedit.so.2.0.68\n",
            "\tlibXfixes.so.3 -> libXfixes.so.3.1.0\n",
            "\tlibvtkParallelMPI-9.1.so.1 -> libvtkParallelMPI-9.1.so.9.1.0\n",
            "\tlibfabric.so.1 -> libfabric.so.1.14.0\n",
            "\tlibcryptsetup.so.12 -> libcryptsetup.so.12.7.0\n",
            "\tlibucm.so.0 -> libucm.so.0.0.0\n",
            "\tlibgfxdr.so.0 -> libgfxdr.so.0.0.1\n",
            "\tlibboost_stacktrace_backtrace.so.1.74.0 -> libboost_stacktrace_backtrace.so.1.74.0\n",
            "\tlibboost_math_tr1f.so.1.74.0 -> libboost_math_tr1f.so.1.74.0\n",
            "\tlibboost_coroutine.so.1.74.0 -> libboost_coroutine.so.1.74.0\n",
            "\tlibvtkCommonMisc-9.1.so.1 -> libvtkCommonMisc-9.1.so.9.1.0\n",
            "\tlibOpenGL.so.0 -> libOpenGL.so.0.0.0\n",
            "\tlibodbccr.so.2 -> libodbccr.so.2.0.0\n",
            "\tlibmlx5.so.1 -> libmlx5.so.1.22.39.0\n",
            "\tlibde265.so.0 -> libde265.so.0.1.1\n",
            "\tlibdrm_radeon.so.1 -> libdrm_radeon.so.1.0.1\n",
            "\tlibbrotlicommon.so.1 -> libbrotlicommon.so.1.0.9\n",
            "\tlibrom1394.so.0 -> librom1394.so.0.3.0\n",
            "\tlibpcsclite.so.1 -> libpcsclite.so.1.0.0\n",
            "\tlibvtkFiltersHyperTree-9.1.so.1 -> libvtkFiltersHyperTree-9.1.so.9.1.0\n",
            "\tlibvtkImagingCore-9.1.so.1 -> libvtkImagingCore-9.1.so.9.1.0\n",
            "\tlibvtkIOPLY-9.1.so.1 -> libvtkIOPLY-9.1.so.9.1.0\n",
            "\tlibopencv_saliency.so.4.5d -> libopencv_saliency.so.4.5.4d\n",
            "\tlibvtkIOMINC-9.1.so.1 -> libvtkIOMINC-9.1.so.9.1.0\n",
            "\tlibglusterfs.so.0 -> libglusterfs.so.0.0.1\n",
            "\tlibIlmImf-2_5.so.25 -> libIlmImf.so\n",
            "\tlibboost_math_c99f.so.1.74.0 -> libboost_math_c99f.so.1.74.0\n",
            "\tlibinfinipath.so.4 -> libinfinipath.so.4.0\n",
            "\tlibmkl_vml_mc.so -> libmkl_vml_mc.so\n",
            "\tlibnetcdf.so.19 -> libnetcdf.so.19\n",
            "\tlibcurl.so.4 -> libcurl.so.4.7.0\n",
            "\tlibvtkFiltersProgrammable-9.1.so.1 -> libvtkFiltersProgrammable-9.1.so.9.1.0\n",
            "\tlibesmumps-6.1.so -> libesmumps-6.1.3.so\n",
            "\tliblept.so.5 -> liblept.so.5.0.4\n",
            "\tlibucs.so.0 -> libucs.so.0.0.0\n",
            "\tlibopencv_imgproc.so.4.5d -> libopencv_imgproc.so.4.5.4d\n",
            "\tlibEGL.so.1 -> libEGL.so.1.1.0\n",
            "\tlibrdmacm.so.1 -> librdmacm.so.1.3.39.0\n",
            "\tlibavahi-client.so.3 -> libavahi-client.so.3.2.9\n",
            "\tlibavcodec.so.58 -> libavcodec.so.58.134.100\n",
            "\tlibXdmcp.so.6 -> libXdmcp.so.6.0.0\n",
            "\tlibgif.so.7 -> libgif.so.7.1.0\n",
            "\tlibopencv_plot.so.4.5d -> libopencv_plot.so.4.5.4d\n",
            "\tlibXcomposite.so.1 -> libXcomposite.so.1.0.0\n",
            "\tlibzmumps-5.4.so -> libzmumps.so\n",
            "\tlibva-drm.so.2 -> libva-drm.so.2.1400.0\n",
            "\tlibx265.so.199 -> libx265.so.199\n",
            "\tlibmbedx509.so.1 -> libmbedx509.so.2.28.0\n",
            "\tlibICE.so.6 -> libICE.so.6.3.0\n",
            "\tlibgthread-2.0.so.0 -> libgthread-2.0.so.0.7200.4\n",
            "\tlibgstfft-1.0.so.0 -> libgstfft-1.0.so.0.2001.0\n",
            "\tlibxcb-glx.so.0 -> libxcb-glx.so.0.0.0\n",
            "\tlibgdk_pixbuf-2.0.so.0 -> libgdk_pixbuf-2.0.so.0.4200.8\n",
            "\tlibxmlb.so.2 -> libxmlb.so.2.0.0\n",
            "\tlibvtkImagingFourier-9.1.so.1 -> libvtkImagingFourier-9.1.so.9.1.0\n",
            "\tlibvtkFiltersParallelMPI-9.1.so.1 -> libvtkFiltersParallelMPI-9.1.so.9.1.0\n",
            "\tlibharfbuzz.so.0 -> libharfbuzz.so.0.20704.0\n",
            "\tlibuv.so.1 -> libuv.so.1.0.0\n",
            "\tlibgstaudio-1.0.so.0 -> libgstaudio-1.0.so.0.2001.0\n",
            "\tlibboost_python310.so.1.74.0 -> libboost_python310.so.1.74.0\n",
            "\tlibkdb5.so.10 -> libkdb5.so.10.0\n",
            "\tlibefa.so.1 -> libefa.so.1.1.39.0\n",
            "\tlibvtkDICOMParser-9.1.so.1 -> libvtkDICOMParser-9.1.so.9.1.0\n",
            "\tlibopenmpt.so.0 -> libopenmpt.so.0.3.3\n",
            "\tlibuct.so.0 -> libuct.so.0.0.0\n",
            "\tlibrhash.so.0 -> librhash.so.0\n",
            "\tlibfyut.so.0 -> libfyut.so.0.0.0\n",
            "\tlibflite_cmu_us_rms.so.1 -> libflite_cmu_us_rms.so.2.2\n",
            "\tlibflite_cmu_grapheme_lang.so.1 -> libflite_cmu_grapheme_lang.so.2.2\n",
            "\tlibavformat.so.58 -> libavformat.so.58.76.100\n",
            "\tlibmpi_mpifh-gfortran.so.40 -> libmpi_mpifh-gfortran.so.40.30.0\n",
            "\tlibmfx.so.1 -> libmfx.so.1.35\n",
            "\tlibGLX_mesa.so.0 -> libGLX_mesa.so.0.0.0\n",
            "\tlibvtkFiltersStatistics-9.1.so.1 -> libvtkFiltersStatistics-9.1.so.9.1.0\n",
            "\tlibboost_iostreams.so.1.74.0 -> libboost_iostreams.so.1.74.0\n",
            "\tlibip4tc.so.2 -> libip4tc.so.2.0.0\n",
            "\tlibgmodule-2.0.so.0 -> libgmodule-2.0.so.0.7200.4\n",
            "\tlibvtkImagingColor-9.1.so.1 -> libvtkImagingColor-9.1.so.9.1.0\n",
            "\tlibmkl_vml_avx.so -> libmkl_vml_avx.so\n",
            "\tlibunwind.so.8 -> libunwind.so.8.0.1\n",
            "\tlibcmumps-5.4.so -> libcmumps.so\n",
            "\tlibXNVCtrl.so.0 -> libXNVCtrl.so.0.0.0\n",
            "\tlibboost_timer.so.1.74.0 -> libboost_timer.so.1.74.0\n",
            "\tlibgdcmMSFF.so.3.0 -> libgdcmMSFF.so.3.0.10\n",
            "\tlibndctl.so.6 -> libndctl.so.6.20.1\n",
            "\tlibtheora.so.0 -> libtheora.so.0.3.10\n",
            "\tlibspeex.so.1 -> libspeex.so.1.5.0\n",
            "\tlibgfortran.so.5 -> libgfortran.so.5.0.0\n",
            "\tlibicutu.so.70 -> libicutu.so.70.1\n",
            "\tlibdrm_amdgpu.so.1 -> libdrm_amdgpu.so.1.0.0\n",
            "\tlibvtkWrappingPythonCore3.10-9.1.so.1 -> libvtkWrappingPythonCore3.10-9.1.so.9.1.0\n",
            "\tlibcfitsio.so.9 -> libcfitsio.so.9.4.0.0\n",
            "\tlibexif.so.12 -> libexif.so.12.3.4\n",
            "\tlibmpi_usempi_ignore_tkr.so.40 -> libmpi_usempi_ignore_tkr.so.40.30.0\n",
            "\tlibopencv_rgbd.so.4.5d -> libopencv_rgbd.so.4.5.4d\n",
            "\tlibminizip.so.1 -> libminizip.so.1.0.0\n",
            "\tlibwayland-cursor.so.0 -> libwayland-cursor.so.0.20.0\n",
            "\tlibfygm.so.0 -> libfygm.so.0.0.0\n",
            "\tlibHalf-2_5.so.25 -> libHalf.so\n",
            "\tliblmdb.so.0 -> liblmdb.so.0.0.0\n",
            "\tlibpython3.10.so.1.0 -> libpython3.10.so.1.0\n",
            "\tlibmumps_common_seq-5.4.so -> libmumps_common_seq.so\n",
            "\tlibsmumps-5.4.so -> libsmumps.so\n",
            "\tlibxcb-dri3.so.0 -> libxcb-dri3.so.0.0.0\n",
            "\tlibpixman-1.so.0 -> libpixman-1.so.0.40.0\n",
            "\tliblilv-0.so.0 -> liblilv-0.so.0.24.12\n",
            "\tlibisc-9.18.30-0ubuntu0.22.04.2-Ubuntu.so -> libisc-9.18.30-0ubuntu0.22.04.2-Ubuntu.so\n",
            "\tlibvtkDomainsChemistryOpenGL2-9.1.so.1 -> libvtkDomainsChemistryOpenGL2-9.1.so.9.1.0\n",
            "\tlibevent_pthreads-2.1.so.7 -> libevent_pthreads.so\n",
            "\tlibdecor-0.so.0 -> libdecor-0.so.0.100.0\n",
            "\tlibdc1394.so.25 -> libdc1394.so.25.0.0\n",
            "\tlibf77blas.so.3 -> libf77blas.so.3.10.3\n",
            "\tlibopencv_dnn.so.4.5d -> libopencv_dnn.so.4.5.4d\n",
            "\tlibvtkIOMPIImage-9.1.so.1 -> libvtkIOMPIImage-9.1.so.9.1.0\n",
            "\tlibvtkCommonColor-9.1.so.1 -> libvtkCommonColor-9.1.so.9.1.0\n",
            "\tlibvtksys-9.1.so.1 -> libvtksys-9.1.so.9.1.0\n",
            "\tlibvtkViewsContext2D-9.1.so.1 -> libvtkViewsContext2D-9.1.so.9.1.0\n",
            "\tlibopencv_dnn_objdetect.so.4.5d -> libopencv_dnn_objdetect.so.4.5.4d\n",
            "\tlibopencv_superres.so.4.5d -> libopencv_superres.so.4.5.4d\n",
            "\tlibvtkIOEnSight-9.1.so.1 -> libvtkIOEnSight-9.1.so.9.1.0\n",
            "\tlibbpf.so.0 -> libbpf.so.0.5.0\n",
            "\tlibdbus-1.so.3 -> libdbus-1.so.3.19.13\n",
            "\tlibblosc.so.1 -> libblosc.so.1.21.1\n",
            "\tlibtcmalloc_minimal.so.4 -> libtcmalloc_minimal.so.4.5.9\n",
            "\tlibvtkIOVeraOut-9.1.so.1 -> libvtkIOVeraOut-9.1.so.9.1.0\n",
            "\tlibsuperlu.so.5 -> libsuperlu.so.5.3.0\n",
            "\tlibcaca++.so.0 -> libcaca++.so.0.99.19\n",
            "\tlibscotcherr-6.1.so -> libscotcherr-6.1.3.so\n",
            "\tlibgdcmjpeg16.so.3.0 -> libgdcmjpeg16.so.3.0.10\n",
            "\tlibmpiseq_seq-5.4.so -> libmpiseq_seq.so\n",
            "\tlibvtkIOImport-9.1.so.1 -> libvtkIOImport-9.1.so.9.1.0\n",
            "\tlibGLX.so.0 -> libGLX.so.0.0.0\n",
            "\tlibpipeline.so.1 -> libpipeline.so.1.5.5\n",
            "\tlibopencv_intensity_transform.so.4.5d -> libopencv_intensity_transform.so.4.5.4d\n",
            "\tlibvtkIOLegacy-9.1.so.1 -> libvtkIOLegacy-9.1.so.9.1.0\n",
            "\tlibjackserver.so.0 -> libjackserver.so.0.0.28\n",
            "\tlibicudata.so.70 -> libicudata.so.70.1\n",
            "\tlibvtkTestingRendering-9.1.so.1 -> libvtkTestingRendering-9.1.so.9.1.0\n",
            "\tlibflite_cmu_us_kal.so.1 -> libflite_cmu_us_kal.so.2.2\n",
            "\tlibvtkDomainsChemistry-9.1.so.1 -> libvtkDomainsChemistry-9.1.so.9.1.0\n",
            "\tlibrtmp.so.1 -> librtmp.so.1\n",
            "\tlibargon2.so.1 -> libargon2.so.1\n",
            "\tliborc-0.4.so.0 -> liborc-0.4.so.0.32.0\n",
            "\tlibmpdec++.so.3 -> libmpdec++.so.2.5.1\n",
            "\tlibvtkViewsCore-9.1.so.1 -> libvtkViewsCore-9.1.so.9.1.0\n",
            "\tlibFLAC.so.8 -> libFLAC.so.8.3.0\n",
            "\tlibboost_thread.so.1.74.0 -> libboost_thread.so.1.74.0\n",
            "\tlibvtkRenderingAnnotation-9.1.so.1 -> libvtkRenderingAnnotation-9.1.so.9.1.0\n",
            "\tlibturbojpeg.so.0 -> libturbojpeg.so.0.2.0\n",
            "\tlibfontenc.so.1 -> libfontenc.so.1.0.0\n",
            "\tlibvtkIOExportPDF-9.1.so.1 -> libvtkIOExportPDF-9.1.so.9.1.0\n",
            "\tlibtheoradec.so.1 -> libtheoradec.so.1.1.4\n",
            "\tlibXmuu.so.1 -> libXmuu.so.1.0.0\n",
            "\tlibboost_stacktrace_addr2line.so.1.74.0 -> libboost_stacktrace_addr2line.so.1.74.0\n",
            "\tlibvtkParallelCore-9.1.so.1 -> libvtkParallelCore-9.1.so.9.1.0\n",
            "\tlibatspi.so.0 -> libatspi.so.0.0.1\n",
            "\tlibmumps_common-5.4.so -> libmumps_common.so\n",
            "\tlibpaper.so.1 -> libpaper.so.1.1.2\n",
            "\tlibgstallocators-1.0.so.0 -> libgstallocators-1.0.so.0.2001.0\n",
            "\tlibkmlregionator.so.1 -> libkmlregionator.so.1.3.0\n",
            "\tlibopencv_alphamat.so.4.5d -> libopencv_alphamat.so.4.5.4d\n",
            "\tlibhdf5_serial_hl_cpp.so.100 -> libhdf5_serial_hl_cpp.so.100.1.5\n",
            "\tlibflite_cmu_us_kal16.so.1 -> libflite_cmu_us_kal16.so.2.2\n",
            "\tlibpulse.so.0 -> libpulse.so.0.24.1\n",
            "\tlibsodium.so.23 -> libsodium.so.23.3.0\n",
            "\tlibvtkRenderingContextOpenGL2-9.1.so.1 -> libvtkRenderingContextOpenGL2-9.1.so.9.1.0\n",
            "\tlibsrt-gnutls.so.1.4 -> libsrt-gnutls.so.1.4.4\n",
            "\tlibpmemobj.so.1 -> libpmemobj.so.1.0.0\n",
            "\tlibzmumps_seq-5.4.so -> libzmumps_seq.so\n",
            "\tlibopenal.so.1 -> libopenal.so.1.19.1\n",
            "\tlibXi.so.6 -> libXi.so.6.1.0\n",
            "\tlibvtkGeovisCore-9.1.so.1 -> libvtkGeovisCore-9.1.so.9.1.0\n",
            "\tlibmkl_vml_cmpt.so -> libmkl_vml_cmpt.so\n",
            "\tlibvtkIOCONVERGECFD-9.1.so.1 -> libvtkIOCONVERGECFD-9.1.so.9.1.0\n",
            "\tlibopencv_ml.so.4.5d -> libopencv_ml.so.4.5.4d\n",
            "\tlibvtkIOSQL-9.1.so.1 -> libvtkIOSQL-9.1.so.9.1.0\n",
            "\tlibmkl_pgi_thread.so -> libmkl_pgi_thread.so\n",
            "\tlibgdk-3.so.0 -> libgdk-3.so.0.2404.29\n",
            "\tlibflite_cmu_us_slt.so.1 -> libflite_cmu_us_slt.so.2.2\n",
            "\tlibpangoft2-1.0.so.0 -> libpangoft2-1.0.so.0.5000.6\n",
            "\tlibatlas.so.3 -> libatlas.so.3.10.3\n",
            "\tlibmkl_avx.so -> libmkl_avx.so\n",
            "\tlibmpi_cxx.so.40 -> libmpi_cxx.so.40.30.1\n",
            "\tlibxcb-sync.so.1 -> libxcb-sync.so.1.0.0\n",
            "\tlibXss.so.1 -> libXss.so.1.0.0\n",
            "\tlibexslt.so.0 -> libexslt.so.0.8.20\n",
            "\tlibGL.so.1 -> libGL.so.1.7.0\n",
            "\tlibXv.so.1 -> libXv.so.1.0.0\n",
            "\tlibprofiler.so.0 -> libprofiler.so.0.5.4\n",
            "\tlibsnappy.so.1 -> libsnappy.so.1.1.8\n",
            "\tlibfontconfig.so.1 -> libfontconfig.so.1.12.0\n",
            "\tlibjson-c.so.5 -> libjson-c.so.5.1.0\n",
            "\tlibjbig.so.0 -> libjbig.so.0\n",
            "\tlibbrotlienc.so.1 -> libbrotlienc.so.1.0.9\n",
            "\tlibGLdispatch.so.0 -> libGLdispatch.so.0.0.0\n",
            "\tliburiparser.so.1 -> liburiparser.so.1.0.29\n",
            "\tlibhwloc.so.15 -> libhwloc.so.15.5.2\n",
            "\tlibmaxminddb.so.0 -> libmaxminddb.so.0.0.7\n",
            "\tlibpathplan.so.4 -> libpathplan.so.4.0.0\n",
            "\tlibexpatw.so.1 -> libexpatw.so.1.8.7\n",
            "\tlibatk-1.0.so.0 -> libatk-1.0.so.0.23609.1\n",
            "\tlibxkbcommon.so.0 -> libxkbcommon.so.0.0.0\n",
            "\tlibpango-1.0.so.0 -> libpango-1.0.so.0.5000.6\n",
            "\tlibsphinxad.so.3 -> libsphinxad.so.3.0.0\n",
            "\tlibboost_mpi_python310.so.1.74.0 -> libboost_mpi_python310.so.1.74.0\n",
            "\tlibvdpau.so.1 -> libvdpau.so.1.0.0\n",
            "\tlibpolkit-agent-1.so.0 -> libpolkit-agent-1.so.0.0.0\n",
            "\tlibgtk-4.so.1 -> libgtk-4.so.1.600.9\n",
            "\tlibmbedtls.so.14 -> libmbedtls.so.2.28.0\n",
            "\tlibvtkCommonDataModel-9.1.so.1 -> libvtkCommonDataModel-9.1.so.9.1.0\n",
            "\tlibgstrtsp-1.0.so.0 -> libgstrtsp-1.0.so.0.2001.0\n",
            "\tlibxcb.so.1 -> libxcb.so.1.1.0\n",
            "\tlibibverbs.so.1 -> libibverbs.so.1.14.39.0\n",
            "\tlibvtkRenderingCore-9.1.so.1 -> libvtkRenderingCore-9.1.so.9.1.0\n",
            "\tlibvtkCommonTransforms-9.1.so.1 -> libvtkCommonTransforms-9.1.so.9.1.0\n",
            "\tlibpython3.11.so.1.0 -> libpython3.11.so.1.0\n",
            "\tlibvtkInfovisCore-9.1.so.1 -> libvtkInfovisCore-9.1.so.9.1.0\n",
            "\tlibXmu.so.6 -> libXmu.so.6.2.0\n",
            "\tlibcdio.so.19 -> libcdio.so.19.0.0\n",
            "\tliboshmem.so.40 -> liboshmem.so.40.30.1\n",
            "\tlibvtkFiltersHybrid-9.1.so.1 -> libvtkFiltersHybrid-9.1.so.9.1.0\n",
            "\tlibulockmgr.so.1 -> libulockmgr.so.1.0.1\n",
            "\tlibsoxr.so.0 -> libsoxr.so.0.1.2\n",
            "\tlibmpg123.so.0 -> libmpg123.so.0.46.7\n",
            "\tlibqhull_r.so.8.0 -> libqhull_r.so.8.0.2\n",
            "\tlibevent_extra-2.1.so.7 -> libevent_extra.so\n",
            "\tlibgstcontroller-1.0.so.0 -> libgstcontroller-1.0.so.0.2003.0\n",
            "\tlibvtkFiltersSelection-9.1.so.1 -> libvtkFiltersSelection-9.1.so.9.1.0\n",
            "\tlibvtkIOImage-9.1.so.1 -> libvtkIOImage-9.1.so.9.1.0\n",
            "\tlibrttopo.so.1 -> librttopo.so.1.1.0\n",
            "\tlibIex-2_5.so.25 -> libIex.so\n",
            "\tlibavc1394.so.0 -> libavc1394.so.0.3.0\n",
            "\tlibvtkIOHDF-9.1.so.1 -> libvtkIOHDF-9.1.so.9.1.0\n",
            "\tlibscotcherrexit-6.1.so -> libscotcherrexit-6.1.3.so\n",
            "\tlibunwind-coredump.so.0 -> libunwind-coredump.so.0.0.0\n",
            "\tlibavfilter.so.7 -> libavfilter.so.7.110.100\n",
            "\tlibopencv_freetype.so.4.5d -> libopencv_freetype.so.4.5.4d\n",
            "\tlibpord_seq-5.4.so -> libpord_seq.so\n",
            "\tlibvtkFiltersSources-9.1.so.1 -> libvtkFiltersSources-9.1.so.9.1.0\n",
            "\tlibpsm2.so.2 -> libpsm2.so.2.2\n",
            "\tlibvtkJava-9.1.so.1 -> libvtkJava-9.1.so.9.1.0\n",
            "\tlibsndfile.so.1 -> libsndfile.so.1.0.31\n",
            "\tlibgphoto2.so.6 -> libgphoto2.so.6.1.0\n",
            "\tlibmkl_vml_mc3.so -> libmkl_vml_mc3.so\n",
            "\tlibcaca.so.0 -> libcaca.so.0.99.19\n",
            "\tlibssh2.so.1 -> libssh2.so.1.0.1\n",
            "\tlibvtkRenderingTk-9.1.so.1 -> libvtkRenderingTk-9.1.so.9.1.0\n",
            "\tlibmfx-tracer.so.1 -> libmfx-tracer.so.1.35\n",
            "\tlibserd-0.so.0 -> libserd-0.so.0.30.10\n",
            "\tlibXau.so.6 -> libXau.so.6.0.0\n",
            "\tlibvtkmetaio-9.1.so.1 -> libvtkmetaio-9.1.so.9.1.0\n",
            "\tlibmkl_intel_ilp64.so -> libmkl_intel_ilp64.so\n",
            "\tliblcms2.so.2 -> liblcms2.so.2.0.12\n",
            "\tlibxcb-randr.so.0 -> libxcb-randr.so.0.1.0\n",
            "\tlibmca_common_verbs.so.40 -> libmca_common_verbs.so.40.30.0\n",
            "\tlibplc4.so -> libplc4.so\n",
            "\tlibboost_log.so.1.74.0 -> libboost_log.so.1.74.0\n",
            "\tlibgdcmDSED.so.3.0 -> libgdcmDSED.so.3.0.10\n",
            "\tlibcolordprivate.so.2 -> libcolordprivate.so.2.0.5\n",
            "\tlibopencv_bgsegm.so.4.5d -> libopencv_bgsegm.so.4.5.4d\n",
            "\tlibxcb-render.so.0 -> libxcb-render.so.0.0.0\n",
            "\tlibboost_math_c99.so.1.74.0 -> libboost_math_c99.so.1.74.0\n",
            "\tlibpmemblk.so.1 -> libpmemblk.so.1.0.0\n",
            "\tlibqhullcpp.so.8.0 -> libqhullcpp.so.8.0.2\n",
            "\tlibdrm_nouveau.so.2 -> libdrm_nouveau.so.2.0.0\n",
            "\tlibtcmalloc.so.4 -> libtcmalloc.so.4.5.9\n",
            "\tlibvtkIOMovie-9.1.so.1 -> libvtkIOMovie-9.1.so.9.1.0\n",
            "\tlibgstrtp-1.0.so.0 -> libgstrtp-1.0.so.0.2001.0\n",
            "\tlibvtkIOCore-9.1.so.1 -> libvtkIOCore-9.1.so.9.1.0\n",
            "\tlibcairo.so.2 -> libcairo.so.2.11600.0\n",
            "\tlibboost_nowide.so.1.74.0 -> libboost_nowide.so.1.74.0\n",
            "\tlibkmldom.so.1 -> libkmldom.so.1.3.0\n",
            "\tlibpmem.so.1 -> libpmem.so.1.0.0\n",
            "\tlibmca_common_ompio.so.41 -> libmca_common_ompio.so.41.29.2\n",
            "\tlibbind9-9.18.30-0ubuntu0.22.04.2-Ubuntu.so -> libbind9-9.18.30-0ubuntu0.22.04.2-Ubuntu.so\n",
            "\tlibvtkFiltersTopology-9.1.so.1 -> libvtkFiltersTopology-9.1.so.9.1.0\n",
            "\tlibyaml-0.so.2 -> libyaml-0.so.2.0.6\n",
            "\tlibvtkIOParallelXML-9.1.so.1 -> libvtkIOParallelXML-9.1.so.9.1.0\n",
            "\tlibdns-9.18.30-0ubuntu0.22.04.2-Ubuntu.so -> libdns-9.18.30-0ubuntu0.22.04.2-Ubuntu.so\n",
            "\tlibgstriff-1.0.so.0 -> libgstriff-1.0.so.0.2001.0\n",
            "\tlibmfxhw64.so.1 -> libmfxhw64.so.1.35\n",
            "\tlibvtkCommonExecutionModel-9.1.so.1 -> libvtkCommonExecutionModel-9.1.so.9.1.0\n",
            "\tlibboost_math_c99l.so.1.74.0 -> libboost_math_c99l.so.1.74.0\n",
            "\tlibtwolame.so.0 -> libtwolame.so.0.0.0\n",
            "\tlibkmlxsd.so.1 -> libkmlxsd.so.1.3.0\n",
            "\tlibvtkRenderingFreeType-9.1.so.1 -> libvtkRenderingFreeType-9.1.so.9.1.0\n",
            "\tlibvtkIOLSDyna-9.1.so.1 -> libvtkIOLSDyna-9.1.so.9.1.0\n",
            "\tlibvtkCommonMath-9.1.so.1 -> libvtkCommonMath-9.1.so.9.1.0\n",
            "\tlibpcrecpp.so.0 -> libpcrecpp.so.0.0.1\n",
            "\tlibopencv_dpm.so.4.5d -> libopencv_dpm.so.4.5.4d\n",
            "\tlibtbbmalloc.so.2 -> libtbbmalloc.so.2.5\n",
            "\tlibwebpdemux.so.2 -> libwebpdemux.so.2.0.9\n",
            "\tlibexpat.so.1 -> libexpat.so.1.8.7\n",
            "\tlibpng16.so.16 -> libpng16.so.16.37.0\n",
            "\tlibevent_openssl-2.1.so.7 -> libevent_openssl.so\n",
            "\tlibgphoto2_port.so.12 -> libgphoto2_port.so.12.0.0\n",
            "\tlibxvidcore.so.4 -> libxvidcore.so.4.3\n",
            "\tlibswscale.so.5 -> libswscale.so.5.9.100\n",
            "\tlibvtkFiltersModeling-9.1.so.1 -> libvtkFiltersModeling-9.1.so.9.1.0\n",
            "\tlibmkl_gnu_thread.so -> libmkl_gnu_thread.so\n",
            "\tlibvtkParallelMPI4Py-9.1.so.1 -> libvtkParallelMPI4Py-9.1.so.9.1.0\n",
            "\tlibgdcmjpeg12.so.3.0 -> libgdcmjpeg12.so.3.0.10\n",
            "\tlibpangoxft-1.0.so.0 -> libpangoxft-1.0.so.0.5000.6\n",
            "\tlibpcre2-32.so.0 -> libpcre2-32.so.0.10.4\n",
            "\tlibvtkIOInfovis-9.1.so.1 -> libvtkIOInfovis-9.1.so.9.1.0\n",
            "\tlibgeos_c.so.1 -> libgeos_c.so.1.17.1\n",
            "\tlibvtkViewsInfovis-9.1.so.1 -> libvtkViewsInfovis-9.1.so.9.1.0\n",
            "\tlibvtkIONetCDF-9.1.so.1 -> libvtkIONetCDF-9.1.so.9.1.0\n",
            "\tlibxslt.so.1 -> libxslt.so.1.1.34\n",
            "\tlibvtkFiltersPython-9.1.so.1 -> libvtkFiltersPython-9.1.so.9.1.0\n",
            "\tlibcmumps_seq-5.4.so -> libcmumps_seq.so\n",
            "\tlibarpack.so.2 -> libarpack.so.2.1.0\n",
            "\tlibgstapp-1.0.so.0 -> libgstapp-1.0.so.0.2001.0\n",
            "\tlibgpm.so.2 -> libgpm.so.2\n",
            "\tlibappstream.so.4 -> libappstream.so.0.15.2\n",
            "\tlibopencv_objdetect.so.4.5d -> libopencv_objdetect.so.4.5.4d\n",
            "\tlibboost_regex.so.1.74.0 -> libboost_regex.so.1.74.0\n",
            "\tlibstemmer.so.0d -> libstemmer.so.0d.0.0\n",
            "\tlibboost_stacktrace_noop.so.1.74.0 -> libboost_stacktrace_noop.so.1.74.0\n",
            "\tlibopencv_reg.so.4.5d -> libopencv_reg.so.4.5.4d\n",
            "\tlibann.so.0 -> libann.so.0.0.0\n",
            "\tlibXaw.so.7 -> libXaw7.so.7.0.0\n",
            "\tlibvtkcgns-9.1.so.1 -> libvtkcgns-9.1.so.9.1.0\n",
            "\tlibIexMath-2_5.so.25 -> libIexMath.so\n",
            "\tlibvtkFiltersFlowPaths-9.1.so.1 -> libvtkFiltersFlowPaths-9.1.so.9.1.0\n",
            "\tlibpord-5.4.so -> libpord.so\n",
            "\tlibopencv_rapid.so.4.5d -> libopencv_rapid.so.4.5.4d\n",
            "\tlibcharls.so.2 -> libcharls.so.2.3.4\n",
            "\tlibraw1394.so.11 -> libraw1394.so.11.1.0\n",
            "\tlibhdf5_serial.so.103 -> libhdf5_serial.so.103.3.0\n",
            "\tlibva-x11.so.2 -> libva-x11.so.2.1400.0\n",
            "\tlibmkl_avx2.so -> libmkl_avx2.so\n",
            "\tlibicui18n.so.70 -> libicui18n.so.70.1\n",
            "\tlibflite_cmulex.so.1 -> libflite_cmulex.so.2.2\n",
            "\tlibglapi.so.0 -> libglapi.so.0.0.0\n",
            "\tlibbluray.so.2 -> libbluray.so.2.4.1\n",
            "\tlibvtkRenderingLabel-9.1.so.1 -> libvtkRenderingLabel-9.1.so.9.1.0\n",
            "\tlibpkgconf.so.3 -> libpkgconf.so.3.0.0\n",
            "\tlibpsl.so.5 -> libpsl.so.5.3.2\n",
            "\tlibevent-2.1.so.7 -> libevent.so\n",
            "\tlibpostproc.so.55 -> libpostproc.so.55.9.100\n",
            "\tlibopencv_aruco.so.4.5d -> libopencv_aruco.so.4.5.4d\n",
            "\tlibmkl_rt.so -> libmkl_rt.so\n",
            "\tlibpgm-5.3.so.0 -> libpgm.so\n",
            "\tlibpopt.so.0 -> libpopt.so.0.0.1\n",
            "\tlibXcursor.so.1 -> libXcursor.so.1.0.2\n",
            "\tlibEGL_mesa.so.0 -> libEGL_mesa.so.0.0.0\n",
            "\tlibmpi_java.so.40 -> libmpi_java.so.40.30.0\n",
            "\tlibasyncns.so.0 -> libasyncns.so.0.3.1\n",
            "\tlibvtkChartsCore-9.1.so.1 -> libvtkChartsCore-9.1.so.9.1.0\n",
            "\tlibgeotiff.so.5 -> libgeotiff.so.5.2.1\n",
            "\tlibboost_graph_parallel.so.1.74.0 -> libboost_graph_parallel.so.1.74.0\n",
            "\tlibmpi.so.40 -> libmpi.so.40.30.2\n",
            "\tlibXft.so.2 -> libXft.so.2.3.4\n",
            "\tlibopencv_ximgproc.so.4.5d -> libopencv_ximgproc.so.4.5.4d\n",
            "\tlibrados.so.2 -> librados.so.2.0.0\n",
            "\tlibqhull.so.8.0 -> libqhull.so.8.0.2\n",
            "\tlibpq.so.5 -> libpq.so.5.14\n",
            "\tlibepoxy.so.0 -> libepoxy.so.0.0.0\n",
            "\tlibpmix.so.2 -> libpmix.so.2.5.2\n",
            "\tlibgobject-2.0.so.0 -> libgobject-2.0.so.0.7200.4\n",
            "\tlibpcre2-16.so.0 -> libpcre2-16.so.0.10.4\n",
            "\tlibpciaccess.so.0 -> libpciaccess.so.0.11.1\n",
            "\tlibopencv_line_descriptor.so.4.5d -> libopencv_line_descriptor.so.4.5.4d\n",
            "\tlibbrotlidec.so.1 -> libbrotlidec.so.1.0.9\n",
            "\tlibdouble-conversion.so.3 -> libdouble-conversion.so.3.1\n",
            "\tlibopencv_dnn_superres.so.4.5d -> libopencv_dnn_superres.so.4.5.4d\n",
            "\tlibsensors.so.5 -> libsensors.so.5.0.0\n",
            "\tlibpolkit-gobject-1.so.0 -> libpolkit-gobject-1.so.0.0.0\n",
            "\tlibboost_wserialization.so.1.74.0 -> libboost_wserialization.so.1.74.0\n",
            "\tlibxcb-shm.so.0 -> libxcb-shm.so.0.0.0\n",
            "\tlibdmumps-5.4.so -> libdmumps.so\n",
            "\tlibopencv_videoio.so.4.5d -> libopencv_videoio.so.4.5.4d\n",
            "\tlibgstbase-1.0.so.0 -> libgstbase-1.0.so.0.2003.0\n",
            "\tlibdatrie.so.1 -> libdatrie.so.1.4.0\n",
            "\tlibkmlbase.so.1 -> libkmlbase.so.1.3.0\n",
            "\tlibpoppler.so.118 -> libpoppler.so.118.0.0\n",
            "\tlibcbor.so.0.8 -> libcbor.so.0.8.0\n",
            "\tlibsmumps_seq-5.4.so -> libsmumps_seq.so\n",
            "\tlibdrm_intel.so.1 -> libdrm_intel.so.1.0.0\n",
            "\tlibwayland-server.so.0 -> libwayland-server.so.0.20.0\n",
            "\tlibvtkParallelDIY-9.1.so.1 -> libvtkParallelDIY-9.1.so.9.1.0\n",
            "\tlibvtkIOCGNSReader-9.1.so.1 -> libvtkIOCGNSReader-9.1.so.9.1.0\n",
            "\tlibvtkverdict-9.1.so.1 -> libvtkverdict-9.1.so.9.1.0\n",
            "\tlibssh.so.4 -> libssh.so.4.8.7\n",
            "\tlibprotobuf.so.23 -> libprotobuf.so.23.0.4\n",
            "\tlibtcl8.6.so -> libtcl8.6.so.0\n",
            "\tlibswresample.so.3 -> libswresample.so.3.9.100\n",
            "\tlibicuio.so.70 -> libicuio.so.70.1\n",
            "\tlibopencv_shape.so.4.5d -> libopencv_shape.so.4.5.4d\n",
            "\tlibvorbisfile.so.3 -> libvorbisfile.so.3.3.8\n",
            "\tlibisccc-9.18.30-0ubuntu0.22.04.2-Ubuntu.so -> libisccc-9.18.30-0ubuntu0.22.04.2-Ubuntu.so\n",
            "\tlibvtkRenderingSceneGraph-9.1.so.1 -> libvtkRenderingSceneGraph-9.1.so.9.1.0\n",
            "\tlibucp.so.0 -> libucp.so.0.0.0\n",
            "\tlibboost_type_erasure.so.1.74.0 -> libboost_type_erasure.so.1.74.0\n",
            "\tlibmbedcrypto.so.7 -> libmbedcrypto.so.2.28.0\n",
            "\tlibicuuc.so.70 -> libicuuc.so.70.1\n",
            "\tlibboost_graph.so.1.74.0 -> libboost_graph.so.1.74.0\n",
            "\tlibmkl_vml_avx512_mic.so -> libmkl_vml_avx512_mic.so\n",
            "\tlibgme.so.0 -> libgme.so.0.6.3\n",
            "\tlibvtkWrappingTools-9.1.so.1 -> libvtkWrappingTools-9.1.so.9.1.0\n",
            "\tlibmca_common_ofi.so.10 -> libmca_common_ofi.so.10.0.2\n",
            "\tlibobjc_gc.so.4 -> libobjc_gc.so.4.0.0\n",
            "\tlibgbm.so.1 -> libgbm.so.1.0.0\n",
            "\tlibImath-2_5.so.25 -> libImath.so\n",
            "\tlibatk-bridge-2.0.so.0 -> libatk-bridge-2.0.so.0.0.0\n",
            "\tlibvtkImagingStencil-9.1.so.1 -> libvtkImagingStencil-9.1.so.9.1.0\n",
            "\tlibhdf5_serialhl_fortran.so.100 -> libhdf5_serialhl_fortran.so.100.0.6\n",
            "\tlibdav1d.so.5 -> libdav1d.so.5.1.1\n",
            "\tlibzvbi-chains.so.0 -> libzvbi-chains.so.0.0.0\n",
            "\tlibtbb.so.12 -> libtbb.so.12.5\n",
            "\tlibwayland-egl.so.1 -> libwayland-egl.so.1.20.0\n",
            "\tlibgd.so.3 -> libgd.so.3.0.8\n",
            "\tlibvpx.so.7 -> libvpx.so.7.0.0\n",
            "\tlibXinerama.so.1 -> libXinerama.so.1.0.0\n",
            "\tlibopen-pal.so.40 -> libopen-pal.so.40.30.2\n",
            "\tlibflite_usenglish.so.1 -> libflite_usenglish.so.2.2\n",
            "\tlibvtkFiltersGeometry-9.1.so.1 -> libvtkFiltersGeometry-9.1.so.9.1.0\n",
            "\tlibgl2ps.so.1.4 -> libgl2ps.so.1.4.2\n",
            "\tlibIlmThread-2_5.so.25 -> libIlmThread.so\n",
            "\tlibopencv_calib3d.so.4.5d -> libopencv_calib3d.so.4.5.4d\n",
            "\tlibdmumps_seq-5.4.so -> libdmumps_seq.so\n",
            "\tlibcgraph.so.6 -> libcgraph.so.6.0.0\n",
            "\tlibgstcheck-1.0.so.0 -> libgstcheck-1.0.so.0.2003.0\n",
            "\tlibmkl_gf_ilp64.so -> libmkl_gf_ilp64.so\n",
            "\tlibopencv_flann.so.4.5d -> libopencv_flann.so.4.5.4d\n",
            "\tlibjack.so.0 -> libjack.so.0.0.28\n",
            "\tlibXrandr.so.2 -> libXrandr.so.2.2.0\n",
            "\tlibgdal.so.32 -> libgdal.so.32.3.6.4\n",
            "\tlibtk8.6.so -> libtk8.6.so.0\n",
            "\tlibvtkRenderingGL2PSOpenGL2-9.1.so.1 -> libvtkRenderingGL2PSOpenGL2-9.1.so.9.1.0\n",
            "\tlibscalapack-openmpi.so.2.1 -> libscalapack-openmpi.so.2.1.0\n",
            "\tlibvtkIOOggTheora-9.1.so.1 -> libvtkIOOggTheora-9.1.so.9.1.0\n",
            "\tlibLLVM-15.so.1 -> libLLVM-15.so.1\n",
            "\tlibavahi-common.so.3 -> libavahi-common.so.3.5.4\n",
            "\tlibgc.so.1 -> libgc.so.1.4.4\n",
            "\tlibrsvg-2.so.2 -> librsvg-2.so.2.48.0\n",
            "\tlibgdcmMEXD.so.3.0 -> libgdcmMEXD.so.3.0.10\n",
            "\tlibGLESv2.so.2 -> libGLESv2.so.2.1.0\n",
            "\tlibvtkDomainsParallelChemistry-9.1.so.1 -> libvtkDomainsParallelChemistry-9.1.so.9.1.0\n",
            "\tlibmkl_def.so -> libmkl_def.so\n",
            "\tlibpcre16.so.3 -> libpcre16.so.3.13.3\n",
            "\tlibmysofa.so.1 -> libmysofa.so.1.1.0\n",
            "\tlibvtkIOTecplotTable-9.1.so.1 -> libvtkIOTecplotTable-9.1.so.9.1.0\n",
            "\tlibmkl_vml_avx2.so -> libmkl_vml_avx2.so\n",
            "\tlibsz.so.2 -> libsz.so.2.0.1\n",
            "\tlibgeos.so.3.11.1 -> libgeos.so.3.11.1\n",
            "\tlibwayland-client.so.0 -> libwayland-client.so.0.20.0\n",
            "\tlibcdt.so.5 -> libcdt.so.5.0.0\n",
            "\tlibxkbfile.so.1 -> libxkbfile.so.1.0.2\n",
            "\tlibevent_core-2.1.so.7 -> libevent_core.so\n",
            "\tlibcblas.so.3 -> libcblas.so.3.10.3\n",
            "\tlibX11.so.6 -> libX11.so.6.4.0\n",
            "\tlibvtkImagingHybrid-9.1.so.1 -> libvtkImagingHybrid-9.1.so.9.1.0\n",
            "\tlibnl-3.so.200 -> libnl-3.so.200.26.0\n",
            "\tlibOpenCL.so.1 -> libOpenCL.so.1.0.0\n",
            "\tlibmkl_avx512_mic.so -> libmkl_avx512_mic.so\n",
            "\tlibsratom-0.so.0 -> libsratom-0.so.0.6.8\n",
            "\tlibclang-14.so.13 -> libclang-14.so.14.0.0\n",
            "\tlibopenjp2.so.7 -> libopenjp2.so.2.4.0\n",
            "\tlibfyba.so.0 -> libfyba.so.0.0.0\n",
            "\tlibopencv_quality.so.4.5d -> libopencv_quality.so.4.5.4d\n",
            "\tlibvtkIOIOSS-9.1.so.1 -> libvtkIOIOSS-9.1.so.9.1.0\n",
            "\tlibmysqlclient.so.21 -> libmysqlclient.so.21.2.41\n",
            "\tlibxcb-present.so.0 -> libxcb-present.so.0.0.0\n",
            "\tlibsndio.so.7 -> libsndio.so.7.1\n",
            "\tlibIlmImfUtil-2_5.so.25 -> libIlmImfUtil.so\n",
            "\tlibplds4.so -> libplds4.so\n",
            "\tlibvtkIOVideo-9.1.so.1 -> libvtkIOVideo-9.1.so.9.1.0\n",
            "\tlibompitrace.so.40 -> libompitrace.so.40.30.0\n",
            "\tlibtcmalloc_debug.so.4 -> libtcmalloc_debug.so.4.5.9\n",
            "\tlibgstvideo-1.0.so.0 -> libgstvideo-1.0.so.0.2001.0\n",
            "\tlibscotchmetis_m5-6.1.so -> libscotchmetis_m5-6.1.3.so\n",
            "\tlibgraphite2.so.3 -> libgraphite2.so.3.2.1\n",
            "\tlibhdf5_serial_cpp.so.103 -> libhdf5_serial_cpp.so.103.3.0\n",
            "\tlibgirepository-1.0.so.1 -> libgirepository-1.0.so.1.0.0\n",
            "\tlibheif.so.1 -> libheif.so.1.12.0\n",
            "\tlibkmlconvenience.so.1 -> libkmlconvenience.so.1.3.0\n",
            "\tlibXxf86vm.so.1 -> libXxf86vm.so.1.0.0\n",
            "\tlibrbd.so.1 -> librbd.so.1.17.0\n",
            "\tlibxcb-dri2.so.0 -> libxcb-dri2.so.0.0.0\n",
            "\tlibvtkFiltersGeneral-9.1.so.1 -> libvtkFiltersGeneral-9.1.so.9.1.0\n",
            "\tlibcurl-gnutls.so.4 -> libcurl-gnutls.so.4.7.0\n",
            "\tlibgsm.so.1 -> libgsm.so.1.0.19\n",
            "\tlibiec61883.so.0 -> libiec61883.so.0.1.1\n",
            "\tlibvtkFiltersAMR-9.1.so.1 -> libvtkFiltersAMR-9.1.so.9.1.0\n",
            "\tlibvtkFiltersParallelVerdict-9.1.so.1 -> libvtkFiltersParallelVerdict-9.1.so.9.1.0\n",
            "\tlibshine.so.3 -> libshine.so.3.0.1\n",
            "\tlibopencv_phase_unwrapping.so.4.5d -> libopencv_phase_unwrapping.so.4.5.4d\n",
            "\tlibgssrpc.so.4 -> libgssrpc.so.4.2\n",
            "\tlibssh-gcrypt.so.4 -> libssh-gcrypt.so.4.8.7\n",
            "\tlibgdcmIOD.so.3.0 -> libgdcmIOD.so.3.0.10\n",
            "\tlibass.so.9 -> libass.so.9.1.3\n",
            "\tlibltdl.so.7 -> libltdl.so.7.3.1\n",
            "\tlibmkl_intel_thread.so -> libmkl_intel_thread.so\n",
            "\tlibboost_log_setup.so.1.74.0 -> libboost_log_setup.so.1.74.0\n",
            "\tlibvtkFiltersParallelImaging-9.1.so.1 -> libvtkFiltersParallelImaging-9.1.so.9.1.0\n",
            "\tlibsord-0.so.0 -> libsord-0.so.0.16.8\n",
            "\tlibunwind-x86_64.so.8 -> libunwind-x86_64.so.8.0.1\n",
            "\tlibssl.so.3 -> libssl.so.3\n",
            "\tlibdb-5.3.so -> libdb-5.3.so\n",
            "\tliblz4.so.1 -> liblz4.so.1.9.3\n",
            "\tlibmvec.so.1 -> libmvec.so.1\n",
            "\tlibpcprofile.so -> libpcprofile.so\n",
            "\tlibsepol.so.2 -> libsepol.so.2\n",
            "\tlibc.so.6 -> libc.so.6\n",
            "\tlibseccomp.so.2 -> libseccomp.so.2.5.3\n",
            "\tlibmemusage.so -> libmemusage.so\n",
            "\tlibudev.so.1 -> libudev.so.1.7.2\n",
            "\tlibnss_files.so.2 -> libnss_files.so.2\n",
            "\tlibc_malloc_debug.so.0 -> libc_malloc_debug.so.0\n",
            "\tlibkrb5support.so.0 -> libkrb5support.so.0.1\n",
            "\tlibstdc++.so.6 -> libstdc++.so.6.0.30\n",
            "\tlibgssapi_krb5.so.2 -> libgssapi_krb5.so.2.2\n",
            "\tlibcrypt.so.1 -> libcrypt.so.1.1.0\n",
            "\tlibdl.so.2 -> libdl.so.2\n",
            "\tlibnsl.so.2 -> libnsl.so.2.0.1\n",
            "\tlibaudit.so.1 -> libaudit.so.1.0.0\n",
            "\tlibnsl.so.1 -> libnsl.so.1\n",
            "\tlibform.so.6 -> libform.so.6.3\n",
            "\tlibsemanage.so.2 -> libsemanage.so.2\n",
            "\tlibapt-private.so.0.0 -> libapt-private.so.0.0.0\n",
            "\tlibnettle.so.8 -> libnettle.so.8.4\n",
            "\tlibpthread.so.0 -> libpthread.so.0\n",
            "\tlibthread_db.so.1 -> libthread_db.so.1\n",
            "\tlibzstd.so.1 -> libzstd.so.1.4.8\n",
            "\tlibgmp.so.10 -> libgmp.so.10.4.1\n",
            "\tlibidn2.so.0 -> libidn2.so.0.3.7\n",
            "/sbin/ldconfig.real: /lib/x86_64-linux-gnu/ld-linux-x86-64.so.2 is the dynamic linker, ignoring\n",
            "\n",
            "\tld-linux-x86-64.so.2 -> ld-linux-x86-64.so.2\n",
            "\tlibp11-kit.so.0 -> libp11-kit.so.0.3.0\n",
            "\tlibattr.so.1 -> libattr.so.1.1.2501\n",
            "\tlibnss_hesiod.so.2 -> libnss_hesiod.so.2\n",
            "\tliblzma.so.5 -> liblzma.so.5.2.5\n",
            "\tlibtinfo.so.6 -> libtinfo.so.6.3\n",
            "\tlibnss_dns.so.2 -> libnss_dns.so.2\n",
            "\tlibkeyutils.so.1 -> libkeyutils.so.1.9\n",
            "\tlibBrokenLocale.so.1 -> libBrokenLocale.so.1\n",
            "\tlibacl.so.1 -> libacl.so.1.1.2301\n",
            "\tlibpam.so.0 -> libpam.so.0.85.1\n",
            "\tlibmenu.so.6 -> libmenu.so.6.3\n",
            "\tlibnss_compat.so.2 -> libnss_compat.so.2\n",
            "\tlibcrypto.so.3 -> libcrypto.so.3\n",
            "\tlibselinux.so.1 -> libselinux.so.1\n",
            "\tlibncurses.so.6 -> libncurses.so.6.3\n",
            "\tlibuuid.so.1 -> libuuid.so.1.3.0\n",
            "\tlibmenuw.so.6 -> libmenuw.so.6.3\n",
            "\tlibgcrypt.so.20 -> libgcrypt.so.20.3.4\n",
            "\tlibpam_misc.so.0 -> libpam_misc.so.0.82.1\n",
            "\tlibrt.so.1 -> librt.so.1\n",
            "\tlibblkid.so.1 -> libblkid.so.1.1.0\n",
            "\tlibcom_err.so.2 -> libcom_err.so.2.1\n",
            "\tlibffi.so.8 -> libffi.so.8.1.0\n",
            "\tlibgcc_s.so.1 -> libgcc_s.so.1\n",
            "\tlibpcreposix.so.3 -> libpcreposix.so.3.13.3\n",
            "\tlibss.so.2 -> libss.so.2.0\n",
            "\tlibgpg-error.so.0 -> libgpg-error.so.0.32.1\n",
            "\tlibpanel.so.6 -> libpanel.so.6.3\n",
            "\tlibpcre.so.3 -> libpcre.so.3.13.3\n",
            "\tlibpamc.so.0 -> libpamc.so.0.82.1\n",
            "\tlibapt-pkg.so.6.0 -> libapt-pkg.so.6.0.0\n",
            "\tlibbz2.so.1.0 -> libbz2.so.1.0.4\n",
            "\tlibprocps.so.8 -> libprocps.so.8.0.3\n",
            "\tlibresolv.so.2 -> libresolv.so.2\n",
            "\tlibkrb5.so.3 -> libkrb5.so.3.3\n",
            "\tlibutil.so.1 -> libutil.so.1\n",
            "\tlibmount.so.1 -> libmount.so.1.1.0\n",
            "\tlibpanelw.so.6 -> libpanelw.so.6.3\n",
            "\tlibformw.so.6 -> libformw.so.6.3\n",
            "\tlibcap-ng.so.0 -> libcap-ng.so.0.0.0\n",
            "\tlibncursesw.so.6 -> libncursesw.so.6.3\n",
            "\tlibtic.so.6 -> libtic.so.6.3\n",
            "\tlibxxhash.so.0 -> libxxhash.so.0.8.1\n",
            "\tlibdebconfclient.so.0 -> libdebconfclient.so.0.0.0\n",
            "\tlibz.so.1 -> libz.so.1.2.11\n",
            "\tlibsmartcols.so.1 -> libsmartcols.so.1.1.0\n",
            "\tlibanl.so.1 -> libanl.so.1\n",
            "\tlibhogweed.so.6 -> libhogweed.so.6.4\n",
            "\tlibext2fs.so.2 -> libext2fs.so.2.4\n",
            "\tlibpcre2-8.so.0 -> libpcre2-8.so.0.10.4\n",
            "\tlibunistring.so.2 -> libunistring.so.2.2.0\n",
            "\tlibcap.so.2 -> libcap.so.2.44\n",
            "\tlibtasn1.so.6 -> libtasn1.so.6.6.2\n",
            "\tlibe2p.so.2 -> libe2p.so.2.3\n",
            "\tlibgnutls.so.30 -> libgnutls.so.30.31.0\n",
            "\tlibsystemd.so.0 -> libsystemd.so.0.32.0\n",
            "\tlibk5crypto.so.3 -> libk5crypto.so.3.1\n",
            "\tlibtirpc.so.3 -> libtirpc.so.3.0.0\n",
            "\tlibm.so.6 -> libm.so.6\n",
            "/lib32: (from /etc/ld.so.conf.d/zz_i386-biarch-compat.conf:2)\n",
            "\tlibpcprofile.so -> libpcprofile.so\n",
            "\tlibc.so.6 -> libc.so.6\n",
            "\tlibmemusage.so -> libmemusage.so\n",
            "\tlibnss_files.so.2 -> libnss_files.so.2\n",
            "\tlibc_malloc_debug.so.0 -> libc_malloc_debug.so.0\n",
            "\tlibstdc++.so.6 -> libstdc++.so.6.0.30\n",
            "\tlibdl.so.2 -> libdl.so.2\n",
            "\tlibnsl.so.1 -> libnsl.so.1\n",
            "\tlibpthread.so.0 -> libpthread.so.0\n",
            "\tlibthread_db.so.1 -> libthread_db.so.1\n",
            "\tlibnss_hesiod.so.2 -> libnss_hesiod.so.2\n",
            "\tlibnss_dns.so.2 -> libnss_dns.so.2\n",
            "\tlibBrokenLocale.so.1 -> libBrokenLocale.so.1\n",
            "\tlibnss_compat.so.2 -> libnss_compat.so.2\n",
            "\tlibrt.so.1 -> librt.so.1\n",
            "\tlibgcc_s.so.1 -> libgcc_s.so.1\n",
            "/sbin/ldconfig.real: /lib32/ld-linux.so.2 is the dynamic linker, ignoring\n",
            "\n",
            "\tld-linux.so.2 -> ld-linux.so.2\n",
            "\tlibresolv.so.2 -> libresolv.so.2\n",
            "\tlibutil.so.1 -> libutil.so.1\n",
            "\tlibanl.so.1 -> libanl.so.1\n",
            "\tlibm.so.6 -> libm.so.6\n",
            "/lib: (from <builtin>:0)\n",
            "\tlibogdi.so.4.1 -> libogdi.so.4.1\n",
            "\tlibipopt.so.1 -> libipopt.so.1.9.9\n",
            "\tlibBLT.2.5.so.8.6 -> libBLT.2.5.so.8.6\n",
            "\tlibmfhdfalt.so.0 -> libmfhdfalt.so.0.0.0\n",
            "\tlibBLTlite.2.5.so.8.6 -> libBLTlite.2.5.so.8.6\n",
            "\tlibvpf.so.4.1 -> libvpf.so.4.1\n",
            "\tlibarmadillo.so.10 -> libarmadillo.so.10.8.2\n",
            "\tlibdfalt.so.0 -> libdfalt.so.0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# download right version of OpenNMT-py"
      ],
      "metadata": {
        "id": "CRQjdKCrrxbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9vWXF1XtHVb",
        "outputId": "7569abde-73b0-4e96-8e4d-c42ac6e1c5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/OpenNMT/OpenNMT-py/archive/refs/tags/2.3.0.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf8ZZDssrwYp",
        "outputId": "45f046ca-30df-41a6-8975-6ed933f24829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-21 14:16:00--  https://github.com/OpenNMT/OpenNMT-py/archive/refs/tags/2.3.0.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/OpenNMT/OpenNMT-py/tar.gz/refs/tags/2.3.0 [following]\n",
            "--2025-04-21 14:16:00--  https://codeload.github.com/OpenNMT/OpenNMT-py/tar.gz/refs/tags/2.3.0\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.116.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.116.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘2.3.0.tar.gz’\n",
            "\n",
            "2.3.0.tar.gz            [             <=>    ]  77.81M  19.6MB/s    in 4.3s    \n",
            "\n",
            "2025-04-21 14:16:05 (18.0 MB/s) - ‘2.3.0.tar.gz’ saved [81586137]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -zxvf 2.3.0.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zBieDjNsCtU",
        "outputId": "f277df0c-25c4-480e-fcdc-a0a478943dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenNMT-py-2.3.0/\n",
            "OpenNMT-py-2.3.0/.github/\n",
            "OpenNMT-py-2.3.0/.github/workflows/\n",
            "OpenNMT-py-2.3.0/.github/workflows/push.yml\n",
            "OpenNMT-py-2.3.0/.github/workflows/release.yml\n",
            "OpenNMT-py-2.3.0/.gitignore\n",
            "OpenNMT-py-2.3.0/CHANGELOG.md\n",
            "OpenNMT-py-2.3.0/CONTRIBUTING.md\n",
            "OpenNMT-py-2.3.0/LICENSE.md\n",
            "OpenNMT-py-2.3.0/README.md\n",
            "OpenNMT-py-2.3.0/SECURITY.md\n",
            "OpenNMT-py-2.3.0/available_models/\n",
            "OpenNMT-py-2.3.0/available_models/example.conf.json\n",
            "OpenNMT-py-2.3.0/build_vocab.py\n",
            "OpenNMT-py-2.3.0/config/\n",
            "OpenNMT-py-2.3.0/config/config-rnn-summarization.yml\n",
            "OpenNMT-py-2.3.0/config/config-transformer-base-1GPU.yml\n",
            "OpenNMT-py-2.3.0/config/config-transformer-base-4GPU.yml\n",
            "OpenNMT-py-2.3.0/data/\n",
            "OpenNMT-py-2.3.0/data/README.md\n",
            "OpenNMT-py-2.3.0/data/align_data.yaml\n",
            "OpenNMT-py-2.3.0/data/data.yaml\n",
            "OpenNMT-py-2.3.0/data/data_features/\n",
            "OpenNMT-py-2.3.0/data/data_features/src-test.feat0\n",
            "OpenNMT-py-2.3.0/data/data_features/src-test.txt\n",
            "OpenNMT-py-2.3.0/data/data_features/src-train.feat0\n",
            "OpenNMT-py-2.3.0/data/data_features/src-train.txt\n",
            "OpenNMT-py-2.3.0/data/data_features/src-val.feat0\n",
            "OpenNMT-py-2.3.0/data/data_features/src-val.txt\n",
            "OpenNMT-py-2.3.0/data/data_features/tgt-train.txt\n",
            "OpenNMT-py-2.3.0/data/data_features/tgt-val.txt\n",
            "OpenNMT-py-2.3.0/data/data_lm/\n",
            "OpenNMT-py-2.3.0/data/data_lm/gen-beam-sol.txt\n",
            "OpenNMT-py-2.3.0/data/data_lm/gen-nucleus-sampling-sol.txt\n",
            "OpenNMT-py-2.3.0/data/data_lm/gen-sampling-beams-sol.txt\n",
            "OpenNMT-py-2.3.0/data/data_lm/gen-sampling-sol.txt\n",
            "OpenNMT-py-2.3.0/data/data_lm/src-gen.txt\n",
            "OpenNMT-py-2.3.0/data/features_data.yaml\n",
            "OpenNMT-py-2.3.0/data/ggnn_data.yaml\n",
            "OpenNMT-py-2.3.0/data/ggnnsrc.txt\n",
            "OpenNMT-py-2.3.0/data/ggnnsrcvocab.txt\n",
            "OpenNMT-py-2.3.0/data/ggnntgt.txt\n",
            "OpenNMT-py-2.3.0/data/ggnntgtvocab.txt\n",
            "OpenNMT-py-2.3.0/data/lm_data.yaml\n",
            "OpenNMT-py-2.3.0/data/morph/\n",
            "OpenNMT-py-2.3.0/data/morph/src.train\n",
            "OpenNMT-py-2.3.0/data/morph/src.valid\n",
            "OpenNMT-py-2.3.0/data/morph/tgt.train\n",
            "OpenNMT-py-2.3.0/data/morph/tgt.valid\n",
            "OpenNMT-py-2.3.0/data/morph_data.yaml\n",
            "OpenNMT-py-2.3.0/data/sample.bpe\n",
            "OpenNMT-py-2.3.0/data/sample.sp.model\n",
            "OpenNMT-py-2.3.0/data/src-test.txt\n",
            "OpenNMT-py-2.3.0/data/src-train.txt\n",
            "OpenNMT-py-2.3.0/data/src-val.txt\n",
            "OpenNMT-py-2.3.0/data/test_model2.src\n",
            "OpenNMT-py-2.3.0/data/test_model2.tgt\n",
            "OpenNMT-py-2.3.0/data/tgt-train.txt\n",
            "OpenNMT-py-2.3.0/data/tgt-val.txt\n",
            "OpenNMT-py-2.3.0/data/val.src-tgt.talp\n",
            "OpenNMT-py-2.3.0/data/vocab-train.src\n",
            "OpenNMT-py-2.3.0/data/vocab-train.tgt\n",
            "OpenNMT-py-2.3.0/docs/\n",
            "OpenNMT-py-2.3.0/docs/Makefile\n",
            "OpenNMT-py-2.3.0/docs/requirements.txt\n",
            "OpenNMT-py-2.3.0/docs/source/\n",
            "OpenNMT-py-2.3.0/docs/source/CONTRIBUTING.md\n",
            "OpenNMT-py-2.3.0/docs/source/FAQ.md\n",
            "OpenNMT-py-2.3.0/docs/source/_static/\n",
            "OpenNMT-py-2.3.0/docs/source/_static/theme_overrides.css\n",
            "OpenNMT-py-2.3.0/docs/source/conf.py\n",
            "OpenNMT-py-2.3.0/docs/source/examples/\n",
            "OpenNMT-py-2.3.0/docs/source/examples/GGNN.md\n",
            "OpenNMT-py-2.3.0/docs/source/examples/LanguageModelGeneration.md\n",
            "OpenNMT-py-2.3.0/docs/source/examples/Library.ipynb\n",
            "OpenNMT-py-2.3.0/docs/source/examples/Library.md\n",
            "OpenNMT-py-2.3.0/docs/source/examples/Summarization.md\n",
            "OpenNMT-py-2.3.0/docs/source/examples/Translation.md\n",
            "OpenNMT-py-2.3.0/docs/source/index.rst\n",
            "OpenNMT-py-2.3.0/docs/source/legacy/\n",
            "OpenNMT-py-2.3.0/docs/source/legacy/FAQ.md\n",
            "OpenNMT-py-2.3.0/docs/source/legacy/im2text.md\n",
            "OpenNMT-py-2.3.0/docs/source/legacy/speech2text.md\n",
            "OpenNMT-py-2.3.0/docs/source/legacy/vid2text.rst\n",
            "OpenNMT-py-2.3.0/docs/source/main.md\n",
            "OpenNMT-py-2.3.0/docs/source/onmt.inputters.rst\n",
            "OpenNMT-py-2.3.0/docs/source/onmt.modules.rst\n",
            "OpenNMT-py-2.3.0/docs/source/onmt.rst\n",
            "OpenNMT-py-2.3.0/docs/source/onmt.translate.translation_server.rst\n",
            "OpenNMT-py-2.3.0/docs/source/onmt.translation.rst\n",
            "OpenNMT-py-2.3.0/docs/source/options/\n",
            "OpenNMT-py-2.3.0/docs/source/options/build_vocab.rst\n",
            "OpenNMT-py-2.3.0/docs/source/options/server.rst\n",
            "OpenNMT-py-2.3.0/docs/source/options/train.rst\n",
            "OpenNMT-py-2.3.0/docs/source/options/translate.rst\n",
            "OpenNMT-py-2.3.0/docs/source/quickstart.md\n",
            "OpenNMT-py-2.3.0/docs/source/ref.rst\n",
            "OpenNMT-py-2.3.0/docs/source/refs.bib\n",
            "OpenNMT-py-2.3.0/examples/\n",
            "OpenNMT-py-2.3.0/examples/cnndm.yaml\n",
            "OpenNMT-py-2.3.0/examples/ggnn.yaml\n",
            "OpenNMT-py-2.3.0/examples/onmt.train.fp16.transformer.yaml\n",
            "OpenNMT-py-2.3.0/examples/scripts/\n",
            "OpenNMT-py-2.3.0/examples/scripts/prepare_wikitext-103_data.sh\n",
            "OpenNMT-py-2.3.0/examples/scripts/prepare_wmt_data.sh\n",
            "OpenNMT-py-2.3.0/examples/wiki_103.yaml\n",
            "OpenNMT-py-2.3.0/examples/wmt14_en_de.yaml\n",
            "OpenNMT-py-2.3.0/onmt/\n",
            "OpenNMT-py-2.3.0/onmt/__init__.py\n",
            "OpenNMT-py-2.3.0/onmt/bin/\n",
            "OpenNMT-py-2.3.0/onmt/bin/__init__.py\n",
            "OpenNMT-py-2.3.0/onmt/bin/average_models.py\n",
            "OpenNMT-py-2.3.0/onmt/bin/build_vocab.py\n",
            "OpenNMT-py-2.3.0/onmt/bin/release_model.py\n",
            "OpenNMT-py-2.3.0/onmt/bin/server.py\n",
            "OpenNMT-py-2.3.0/onmt/bin/train.py\n",
            "OpenNMT-py-2.3.0/onmt/bin/translate.py\n",
            "OpenNMT-py-2.3.0/onmt/bin/translate_dynamic.py\n",
            "OpenNMT-py-2.3.0/onmt/constants.py\n",
            "OpenNMT-py-2.3.0/onmt/decoders/\n",
            "OpenNMT-py-2.3.0/onmt/decoders/__init__.py\n",
            "OpenNMT-py-2.3.0/onmt/decoders/cnn_decoder.py\n",
            "OpenNMT-py-2.3.0/onmt/decoders/decoder.py\n",
            "OpenNMT-py-2.3.0/onmt/decoders/ensemble.py\n",
            "OpenNMT-py-2.3.0/onmt/decoders/transformer.py\n",
            "OpenNMT-py-2.3.0/onmt/encoders/\n",
            "OpenNMT-py-2.3.0/onmt/encoders/__init__.py\n",
            "OpenNMT-py-2.3.0/onmt/encoders/cnn_encoder.py\n",
            "OpenNMT-py-2.3.0/onmt/encoders/encoder.py\n",
            "OpenNMT-py-2.3.0/onmt/encoders/ggnn_encoder.py\n",
            "OpenNMT-py-2.3.0/onmt/encoders/mean_encoder.py\n",
            "OpenNMT-py-2.3.0/onmt/encoders/rnn_encoder.py\n",
            "OpenNMT-py-2.3.0/onmt/encoders/transformer.py\n",
            "OpenNMT-py-2.3.0/onmt/inputters/\n",
            "OpenNMT-py-2.3.0/onmt/inputters/__init__.py\n",
            "OpenNMT-py-2.3.0/onmt/inputters/corpus.py\n",
            "OpenNMT-py-2.3.0/onmt/inputters/datareader_base.py\n",
            "OpenNMT-py-2.3.0/onmt/inputters/dataset_base.py\n",
            "OpenNMT-py-2.3.0/onmt/inputters/dynamic_iterator.py\n",
            "OpenNMT-py-2.3.0/onmt/inputters/fields.py\n",
            "OpenNMT-py-2.3.0/onmt/inputters/inputter.py\n",
            "OpenNMT-py-2.3.0/onmt/inputters/iterator.py\n",
            "OpenNMT-py-2.3.0/onmt/inputters/text_dataset.py\n",
            "OpenNMT-py-2.3.0/onmt/model_builder.py\n",
            "OpenNMT-py-2.3.0/onmt/models/\n",
            "OpenNMT-py-2.3.0/onmt/models/__init__.py\n",
            "OpenNMT-py-2.3.0/onmt/models/model.py\n",
            "OpenNMT-py-2.3.0/onmt/models/model_saver.py\n",
            "OpenNMT-py-2.3.0/onmt/models/sru.py\n",
            "OpenNMT-py-2.3.0/onmt/models/stacked_rnn.py\n",
            "OpenNMT-py-2.3.0/onmt/modules/\n",
            "OpenNMT-py-2.3.0/onmt/modules/__init__.py\n",
            "OpenNMT-py-2.3.0/onmt/modules/average_attn.py\n",
            "OpenNMT-py-2.3.0/onmt/modules/conv_multi_step_attention.py\n",
            "OpenNMT-py-2.3.0/onmt/modules/copy_generator.py\n",
            "OpenNMT-py-2.3.0/onmt/modules/embeddings.py\n",
            "OpenNMT-py-2.3.0/onmt/modules/gate.py\n",
            "OpenNMT-py-2.3.0/onmt/modules/global_attention.py\n",
            "OpenNMT-py-2.3.0/onmt/modules/multi_headed_attn.py\n",
            "OpenNMT-py-2.3.0/onmt/modules/position_ffn.py\n",
            "OpenNMT-py-2.3.0/onmt/modules/sparse_activations.py\n",
            "OpenNMT-py-2.3.0/onmt/modules/sparse_losses.py\n",
            "OpenNMT-py-2.3.0/onmt/modules/structured_attention.py\n",
            "OpenNMT-py-2.3.0/onmt/modules/util_class.py\n",
            "OpenNMT-py-2.3.0/onmt/modules/weight_norm.py\n",
            "OpenNMT-py-2.3.0/onmt/opts.py\n",
            "OpenNMT-py-2.3.0/onmt/scorers/\n",
            "OpenNMT-py-2.3.0/onmt/scorers/__init__.py\n",
            "OpenNMT-py-2.3.0/onmt/scorers/bleu.py\n",
            "OpenNMT-py-2.3.0/onmt/scorers/scorer.py\n",
            "OpenNMT-py-2.3.0/onmt/scorers/ter.py\n",
            "OpenNMT-py-2.3.0/onmt/tests/\n",
            "OpenNMT-py-2.3.0/onmt/tests/__init__.py\n",
            "OpenNMT-py-2.3.0/onmt/tests/output_hyp.txt\n",
            "OpenNMT-py-2.3.0/onmt/tests/pull_request_chk.sh\n",
            "OpenNMT-py-2.3.0/onmt/tests/rebuild_test_models.sh\n",
            "OpenNMT-py-2.3.0/onmt/tests/sample_glove.txt\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_attention.py\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_beam_search.py\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_copy_generator.py\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_data_prepare.py\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_embeddings.py\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_greedy_search.py\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_model.pt\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_model2.pt\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_model_lm.pt\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_models.py\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_models.sh\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_simple.py\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_structured_attention.py\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_subword_marker.py\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_text_dataset.py\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_transform.py\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_translation_server.py\n",
            "OpenNMT-py-2.3.0/onmt/tests/test_translator.py\n",
            "OpenNMT-py-2.3.0/onmt/tests/utils_for_tests.py\n",
            "OpenNMT-py-2.3.0/onmt/train_single.py\n",
            "OpenNMT-py-2.3.0/onmt/trainer.py\n",
            "OpenNMT-py-2.3.0/onmt/transforms/\n",
            "OpenNMT-py-2.3.0/onmt/transforms/__init__.py\n",
            "OpenNMT-py-2.3.0/onmt/transforms/bart.py\n",
            "OpenNMT-py-2.3.0/onmt/transforms/features.py\n",
            "OpenNMT-py-2.3.0/onmt/transforms/misc.py\n",
            "OpenNMT-py-2.3.0/onmt/transforms/sampling.py\n",
            "OpenNMT-py-2.3.0/onmt/transforms/tokenize.py\n",
            "OpenNMT-py-2.3.0/onmt/transforms/transform.py\n",
            "OpenNMT-py-2.3.0/onmt/translate/\n",
            "OpenNMT-py-2.3.0/onmt/translate/__init__.py\n",
            "OpenNMT-py-2.3.0/onmt/translate/beam_search.py\n",
            "OpenNMT-py-2.3.0/onmt/translate/decode_strategy.py\n",
            "OpenNMT-py-2.3.0/onmt/translate/greedy_search.py\n",
            "OpenNMT-py-2.3.0/onmt/translate/penalties.py\n",
            "OpenNMT-py-2.3.0/onmt/translate/process_zh.py\n",
            "OpenNMT-py-2.3.0/onmt/translate/translation.py\n",
            "OpenNMT-py-2.3.0/onmt/translate/translation_server.py\n",
            "OpenNMT-py-2.3.0/onmt/translate/translator.py\n",
            "OpenNMT-py-2.3.0/onmt/translate/utils.py\n",
            "OpenNMT-py-2.3.0/onmt/utils/\n",
            "OpenNMT-py-2.3.0/onmt/utils/__init__.py\n",
            "OpenNMT-py-2.3.0/onmt/utils/alignment.py\n",
            "OpenNMT-py-2.3.0/onmt/utils/cnn_factory.py\n",
            "OpenNMT-py-2.3.0/onmt/utils/distributed.py\n",
            "OpenNMT-py-2.3.0/onmt/utils/earlystopping.py\n",
            "OpenNMT-py-2.3.0/onmt/utils/logging.py\n",
            "OpenNMT-py-2.3.0/onmt/utils/loss.py\n",
            "OpenNMT-py-2.3.0/onmt/utils/misc.py\n",
            "OpenNMT-py-2.3.0/onmt/utils/optimizers.py\n",
            "OpenNMT-py-2.3.0/onmt/utils/parse.py\n",
            "OpenNMT-py-2.3.0/onmt/utils/report_manager.py\n",
            "OpenNMT-py-2.3.0/onmt/utils/rnn_factory.py\n",
            "OpenNMT-py-2.3.0/onmt/utils/statistics.py\n",
            "OpenNMT-py-2.3.0/requirements.opt.txt\n",
            "OpenNMT-py-2.3.0/server.py\n",
            "OpenNMT-py-2.3.0/setup.py\n",
            "OpenNMT-py-2.3.0/tools/\n",
            "OpenNMT-py-2.3.0/tools/LM_scoring.py\n",
            "OpenNMT-py-2.3.0/tools/README.md\n",
            "OpenNMT-py-2.3.0/tools/apply_bpe.py\n",
            "OpenNMT-py-2.3.0/tools/average_models.py\n",
            "OpenNMT-py-2.3.0/tools/bpe_pipeline.sh\n",
            "OpenNMT-py-2.3.0/tools/embeddings_to_torch.py\n",
            "OpenNMT-py-2.3.0/tools/extract_embeddings.py\n",
            "OpenNMT-py-2.3.0/tools/extract_vocabulary.py\n",
            "OpenNMT-py-2.3.0/tools/learn_bpe.py\n",
            "OpenNMT-py-2.3.0/tools/mbr_bleu.py\n",
            "OpenNMT-py-2.3.0/tools/multi-bleu-detok.perl\n",
            "OpenNMT-py-2.3.0/tools/oracle_bleu.py\n",
            "OpenNMT-py-2.3.0/tools/oracle_comet.py\n",
            "OpenNMT-py-2.3.0/tools/release_model.py\n",
            "OpenNMT-py-2.3.0/tools/spm_to_vocab.py\n",
            "OpenNMT-py-2.3.0/tools/test_rouge.py\n",
            "OpenNMT-py-2.3.0/train.py\n",
            "OpenNMT-py-2.3.0/translate.py\n",
            "OpenNMT-py-2.3.0/translate_dynamic.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv OpenNMT-py-2.3.0 OpenNMT-py"
      ],
      "metadata": {
        "id": "P0vgyympsMOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd OpenNMT-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsAK-DOfsP2b",
        "outputId": "4ab50e77-efd5-47e3-aaf9-608a72b55f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sentencepiece/build/OpenNMT-py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prepare OpenNMT-py env"
      ],
      "metadata": {
        "id": "QxWXyUDIsoNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPTJAK-3sS9J",
        "outputId": "55c0d2a3-949b-450e-a68b-5c75dcdb7e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/sentencepiece/build/OpenNMT-py\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py==2.3.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchtext==0.5.0 in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py==2.3.0) (0.5.0)\n",
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py==2.3.0) (1.7)\n",
            "Requirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py==2.3.0) (2.18.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py==2.3.0) (3.1.0)\n",
            "Requirement already satisfied: waitress in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: pyonmttok<2,>=1.23 in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py==2.3.0) (1.37.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py==2.3.0) (6.0.2)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py==2.3.0) (2.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.5.0->OpenNMT-py==2.3.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.5.0->OpenNMT-py==2.3.0) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.5.0->OpenNMT-py==2.3.0) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from torchtext==0.5.0->OpenNMT-py==2.3.0) (1.17.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from torchtext==0.5.0->OpenNMT-py==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.3.0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.3.0) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.3.0) (3.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.3.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.3.0) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.3.0) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.3.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.3.0) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->OpenNMT-py==2.3.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->OpenNMT-py==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask->OpenNMT-py==2.3.0) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask->OpenNMT-py==2.3.0) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask->OpenNMT-py==2.3.0) (1.9.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py==2.3.0) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py==2.3.0) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py==2.3.0) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py==2.3.0) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py==2.3.0) (5.3.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->OpenNMT-py==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py==2.3.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py==2.3.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py==2.3.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py==2.3.0) (2025.1.31)\n",
            "Installing collected packages: OpenNMT-py\n",
            "  Attempting uninstall: OpenNMT-py\n",
            "    Found existing installation: OpenNMT-py 2.3.0\n",
            "    Uninstalling OpenNMT-py-2.3.0:\n",
            "      Successfully uninstalled OpenNMT-py-2.3.0\n",
            "  Running setup.py develop for OpenNMT-py\n",
            "Successfully installed OpenNMT-py-2.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv-5ih5YsVpl",
        "outputId": "ffdd4bf6-e4ad-4f3f-bea6-080505ea095c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'keras<3.0.0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S7Ij_ddscAb",
        "outputId": "f7cfd80f-cb7d-401d-8cd2-49d8887e2636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras<3.0.0 in /usr/local/lib/python3.11/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe-model-maker --no-deps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbcLQXNmsdXb",
        "outputId": "971eadb8-ab15-48fd-d996-f53ba9dc5631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe-model-maker in /usr/local/lib/python3.11/dist-packages (0.2.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdkkYkyLsiM7",
        "outputId": "6f5231e8-ad0f-4851-a374-c45b2d97e73e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K6d7XzAsiqL",
        "outputId": "7376450b-75aa-40af-d0a0-85819337f243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# start coding"
      ],
      "metadata": {
        "id": "TRMVJULks4_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vv-Bq8ss6VF",
        "outputId": "5da2b3f2-5350-4347-ebe5-68bf5373f063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# get a target_source.txt file (where target sentence and source sentence seperate by tab)"
      ],
      "metadata": {
        "id": "xy57g1AGt2i7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##I prepare for u english-ede as target_source.txt but u can also pick up any other target_source.txt file . For example: file ALL_mtet.txt here , https://huggingface.co/datasets/WandererGuy/MTet/tree/main"
      ],
      "metadata": {
        "id": "xIXLb9N-zPiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# a file\n",
        "url = \"https://drive.google.com/file/d/1Jnno61GpUKUo_zjfqn3Gj_z9P63bS-TP/view?usp=sharing\"\n",
        "output = \"target_source.txt\"\n",
        "gdown.download(url=url, output=output, fuzzy=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "RPFIMA5kucJz",
        "outputId": "eb3e0393-0d3d-4c6c-95b9-4aacc87965a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Jnno61GpUKUo_zjfqn3Gj_z9P63bS-TP\n",
            "To: /content/target_source.txt\n",
            "100%|██████████| 4.99M/4.99M [00:00<00:00, 19.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'target_source.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "x8TKQsn_u-OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv target_source.txt data/"
      ],
      "metadata": {
        "id": "GxhMqKHvvAkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sample first n or 2 million sentences to train tokenizer"
      ],
      "metadata": {
        "id": "LhLgO4l4tf4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "file_paths = [\n",
        "\"vocab/example.vocab.src\",\n",
        "\"vocab/example.vocab.tgt\",\n",
        "\"target.model\",\n",
        "\"source.model\",\n",
        "\"source.vocab\",\n",
        "\"target.vocab\"\n",
        "]\n",
        "for file_path in file_paths:\n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)\n",
        "\n",
        "path = \"data/target_source.txt\"\n",
        "with open (path, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    num_lines = len(lines)\n",
        "    for line in lines:\n",
        "        line = line.strip(\"\\n\")\n",
        "        tab_count = line.count('\\t')\n",
        "        if tab_count != 1:\n",
        "            raise Exception(\"each line must have 1 tab only between source and target sentence\")\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "if num_lines < 2000000:\n",
        "  max_num = num_lines\n",
        "else:\n",
        "  max_num = 2000000\n",
        "# sample 2000000 sentence for train tokenizer\n",
        "path = \"data/target_source.txt\"\n",
        "with open (path, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    source_single_line_ls = []\n",
        "    target_single_line_ls = []\n",
        "    for line in lines:\n",
        "        line = line.strip(\"\\n\")\n",
        "        target, source = line.split(\"\\t\")\n",
        "        source_single_line_ls.append(source)\n",
        "        target_single_line_ls.append(target)\n",
        "source_dest_path = \"data/source.txt\"\n",
        "new_source_single_line_ls = random.sample(source_single_line_ls, max_num)\n",
        "new_target_single_line_ls = random.sample(target_single_line_ls, max_num)\n",
        "with open (source_dest_path, \"w\") as f:\n",
        "    for index, line in enumerate(new_source_single_line_ls):\n",
        "        f.write(line)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "\n",
        "target_dest_path = \"data/target.txt\"\n",
        "with open (target_dest_path, \"w\") as f:\n",
        "    for index, line in enumerate(new_target_single_line_ls):\n",
        "        f.write(line)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1Fl3f-X6tTKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train sentencepiece to become new tokenizer to use later on for tokenize(segment) raw text (also, so that we dont have <unk> symbol later on)"
      ],
      "metadata": {
        "id": "6e8cP1dHwhkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import time\n",
        "def train_source_spm(vocab_size):\n",
        "    command = f\"spm_train --input=data/source.txt --model_prefix=source --vocab_size={vocab_size} --character_coverage=1.0 --model_type=unigram\"\n",
        "    try:\n",
        "        # Run the command, capturing both stdout and stderr\n",
        "        result = subprocess.run(\n",
        "            command,\n",
        "            shell=True,\n",
        "            check=True,\n",
        "            text=True,\n",
        "            capture_output=True   # ← capture stdout/stderr instead of printing immediately\n",
        "        )\n",
        "\n",
        "        # The captured text is available as result.stdout (and result.stderr)\n",
        "        print(\"STDOUT:\")\n",
        "        print(result.stdout)\n",
        "\n",
        "        print(\"STDERR:\")\n",
        "        print(result.stderr)\n",
        "\n",
        "        return True\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        return False\n",
        "def train_target_spm(vocab_size):\n",
        "    command = f\"spm_train --input=data/target.txt --model_prefix=target --vocab_size={vocab_size} --character_coverage=1.0 --model_type=unigram\"\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            command,\n",
        "            shell=True,\n",
        "            check=True,\n",
        "            text=True,\n",
        "            capture_output=True   # ← capture stdout/stderr instead of printing immediately\n",
        "        )\n",
        "\n",
        "        # The captured text is available as result.stdout (and result.stderr)\n",
        "        print(\"STDOUT:\")\n",
        "        print(result.stdout)\n",
        "\n",
        "        print(\"STDERR:\")\n",
        "        print(result.stderr)\n",
        "        return True\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        return False"
      ],
      "metadata": {
        "id": "Fgqf_zzcvm4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for vocab_size in [8000, 4000, 2000]:\n",
        "    if train_source_spm(vocab_size) == False:\n",
        "        print (\"******************** reduce vocab size ********************\")\n",
        "        time.sleep(5)\n",
        "        continue\n",
        "    else:\n",
        "        break\n",
        "\n",
        "for vocab_size in [8000, 4000, 2000]:\n",
        "    if train_target_spm(vocab_size) == False:\n",
        "        print (\"******************** reduce vocab size ********************\")\n",
        "        time.sleep(5)\n",
        "        continue\n",
        "    else:\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LIqqIcCu7FP",
        "outputId": "6380fc86-80a5-4643-9277-1abc3b1bc7e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************** reduce vocab size ********************\n",
            "STDOUT:\n",
            "\n",
            "STDERR:\n",
            "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: data/source.txt\n",
            "  input_format: \n",
            "  model_prefix: source\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 4000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 1\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  seed_sentencepieces_file: \n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(185) LOG(INFO) Loading corpus: data/source.txt\n",
            "trainer_interface.cc(409) LOG(INFO) Loaded all 17548 sentences\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(539) LOG(INFO) all chars count=2324190\n",
            "trainer_interface.cc(560) LOG(INFO) Alphabet size=86\n",
            "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
            "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 17548 sentences.\n",
            "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=1244170\n",
            "unigram_model_trainer.cc(312) LOG(INFO) Initialized 9955 seed sentencepieces\n",
            "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 17548\n",
            "trainer_interface.cc(609) LOG(INFO) Done! 11580\n",
            "unigram_model_trainer.cc(602) LOG(INFO) Using 11580 sentences for EM training\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=5791 obj=9.04379 num_tokens=29191 num_tokens/piece=5.04075\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=4653 obj=7.29462 num_tokens=29025 num_tokens/piece=6.23791\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=4308 obj=7.22165 num_tokens=29023 num_tokens/piece=6.737\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=4286 obj=7.21456 num_tokens=29041 num_tokens/piece=6.77578\n",
            "trainer_interface.cc(687) LOG(INFO) Saving model: source.model\n",
            "trainer_interface.cc(699) LOG(INFO) Saving vocabs: source.vocab\n",
            "\n",
            "STDOUT:\n",
            "\n",
            "STDERR:\n",
            "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: data/target.txt\n",
            "  input_format: \n",
            "  model_prefix: target\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 8000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 1\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  seed_sentencepieces_file: \n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(185) LOG(INFO) Loading corpus: data/target.txt\n",
            "trainer_interface.cc(409) LOG(INFO) Loaded all 17548 sentences\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(539) LOG(INFO) all chars count=2251119\n",
            "trainer_interface.cc(560) LOG(INFO) Alphabet size=75\n",
            "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
            "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 17548 sentences.\n",
            "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=1262664\n",
            "unigram_model_trainer.cc(312) LOG(INFO) Initialized 31110 seed sentencepieces\n",
            "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 17548\n",
            "trainer_interface.cc(609) LOG(INFO) Done! 22887\n",
            "unigram_model_trainer.cc(602) LOG(INFO) Using 22887 sentences for EM training\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=11734 obj=9.52901 num_tokens=44672 num_tokens/piece=3.80706\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9525 obj=7.53296 num_tokens=44796 num_tokens/piece=4.70299\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=8800 obj=7.46578 num_tokens=45062 num_tokens/piece=5.12068\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=8777 obj=7.45433 num_tokens=45066 num_tokens/piece=5.13456\n",
            "trainer_interface.cc(687) LOG(INFO) Saving model: target.model\n",
            "trainer_interface.cc(699) LOG(INFO) Saving vocabs: target.vocab\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have target.model (which is tokenizer for target.txt) and source.model (which is tokenizer for source.txt)"
      ],
      "metadata": {
        "id": "TczIMUI_wz20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tokenize dataset and prepare dataset for OpenNMT"
      ],
      "metadata": {
        "id": "8XBPBEZCxLSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## split dataset"
      ],
      "metadata": {
        "id": "OT_I8NqpxUB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def split_data(path, train_num, val_num, test_num):\n",
        "    vn_kmer_txt = open(path, mode='r', encoding='utf8')\n",
        "    src_train = open('./data/src-train.txt', mode='w+', encoding='utf8')\n",
        "    tgt_train = open('./data/tgt-train.txt', mode='w+', encoding='utf8')\n",
        "    src_val = open('./data/src-val.txt', mode='w+', encoding='utf8')\n",
        "    tgt_val = open('./data/tgt-val.txt', mode='w+', encoding='utf8')\n",
        "    src_test = open('./data/src-test.txt', mode='w+', encoding='utf8')\n",
        "    tgt_test = open('./data/tgt-test.txt', mode='w+', encoding='utf8')\n",
        "\n",
        "    if (vn_kmer_txt != None):\n",
        "        print('Mở thành công file dữ liệu')\n",
        "\n",
        "    l = 0\n",
        "    n = 0\n",
        "\n",
        "    for line in vn_kmer_txt:\n",
        "        data = line.split('\\t')\n",
        "        if (len(data) < 2):\n",
        "            l += 1\n",
        "            continue\n",
        "        if (n < val_num):\n",
        "            src_val.write(data[-1])\n",
        "            tgt_val.write(data[0] + '\\n')\n",
        "        elif (n < train_num + val_num):\n",
        "            src_train.write(data[-1])\n",
        "            tgt_train.write(data[0]  + '\\n')\n",
        "        else:\n",
        "            src_test.write(data[-1])\n",
        "            tgt_test.write(data[0] + '\\n')\n",
        "        l += 1\n",
        "        n += 1\n",
        "\n",
        "    print('Số lượng dòng tổng cộng là ', l)\n",
        "    print('Số lượng dòng đúng quy tắc có thể tách là ', n)\n",
        "    print ('Số lượng dòng trong train ', train_num)\n",
        "    print ('Số lượng dòng trong val', val_num)\n",
        "    print ('Số lượng dòng trong test ', test_num)\n",
        "\n",
        "import os\n",
        "os.makedirs('./data', exist_ok=True)\n",
        "path = './data/target_source.txt'\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "# Read the lines of the file\n",
        "with open(path, 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Shuffle the lines\n",
        "random.shuffle(lines)\n",
        "\n",
        "# Write the shuffled lines back to a file (or overwrite the same file)\n",
        "with open(path, 'w', encoding='utf-8') as file:\n",
        "    file.writelines(lines)\n",
        "\n",
        "with open(path, mode='r', encoding='utf8') as f:\n",
        "    lines = f.readlines()\n",
        "    total_num = len(lines)\n",
        "    train_num = int(total_num * 0.8)\n",
        "    val_num = int(total_num * 0.1)\n",
        "    test_num = total_num - train_num - val_num\n",
        "\n",
        "split_data(path, train_num, val_num, test_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYU64JujxOlv",
        "outputId": "e2b6de77-119c-4e66-f343-c430062e6951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mở thành công file dữ liệu\n",
            "Số lượng dòng tổng cộng là  17548\n",
            "Số lượng dòng đúng quy tắc có thể tách là  17548\n",
            "Số lượng dòng trong train  14038\n",
            "Số lượng dòng trong val 1754\n",
            "Số lượng dòng trong test  1756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tokenize splited dataset"
      ],
      "metadata": {
        "id": "Tc_EBjXkxZ4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "\n",
        "def tokenize_file(input_file, output_file):\n",
        "    model_name = \"source\"\n",
        "    command = [\"spm_encode\",\n",
        "                f\"--model={model_name}.model\",\n",
        "                \"--input\", input_file,\n",
        "                \"--output\", output_file]\n",
        "\n",
        "    print (\" \".join(command))\n",
        "    # Running the subprocess with the provided command\n",
        "    result = subprocess.run(command, capture_output=True, text=True)\n",
        "\n",
        "src_train = open('./data/src-train.txt', mode='r', encoding='utf8')\n",
        "src_val = open('./data/src-val.txt', mode='r', encoding='utf8')\n",
        "src_test = open('./data/src-test.txt', mode='r', encoding='utf8')\n",
        "\n",
        "# src_train_token = open('./data/src-train-token.txt', mode='w+', encoding='utf8')\n",
        "# src_val_token = open('./data/src-val-token.txt', mode='w+', encoding='utf8')\n",
        "# src_test_token = open('./data/src-test-token.txt', mode='w+', encoding='utf8')\n",
        "\n",
        "tokenize_file('./data/src-train.txt', './data/src-train-token.txt')\n",
        "tokenize_file('./data/src-val.txt', './data/src-val-token.txt')\n",
        "tokenize_file('./data/src-test.txt', './data/src-test-token.txt')\n",
        "\n",
        "n = 0\n",
        "for line in src_train:\n",
        "    n+=1\n",
        "print('Số lượng câu trong tập huấn luyện đích là ', n)\n",
        "n = 0\n",
        "for line in src_val:\n",
        "    n+=1\n",
        "print('Số lượng câu trong tập thẩm định đích là ', n)\n",
        "n = 0\n",
        "for line in src_test:\n",
        "    n+=1\n",
        "print('Số lượng câu trong tập kiểm tra đích là ', n)\n",
        "print(\"Tokenize sucess\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_WAVIp4xYs7",
        "outputId": "7d93b91f-b60e-4d3a-c7b6-683c20ca18f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spm_encode --model=source.model --input ./data/src-train.txt --output ./data/src-train-token.txt\n",
            "spm_encode --model=source.model --input ./data/src-val.txt --output ./data/src-val-token.txt\n",
            "spm_encode --model=source.model --input ./data/src-test.txt --output ./data/src-test-token.txt\n",
            "Số lượng câu trong tập huấn luyện đích là  14038\n",
            "Số lượng câu trong tập thẩm định đích là  1754\n",
            "Số lượng câu trong tập kiểm tra đích là  1756\n",
            "Tokenize sucess\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "\n",
        "def tokenize_file(input_file, output_file):\n",
        "    model_name = \"target\"\n",
        "    command = [\"spm_encode\",\n",
        "                f\"--model={model_name}.model\",\n",
        "                \"--input\", input_file,\n",
        "                \"--output\", output_file]\n",
        "    print (\" \".join(command))\n",
        "    # Running the subprocess with the provided command\n",
        "    result = subprocess.run(command, capture_output=True, text=True)\n",
        "\n",
        "tgt_train = open('./data/tgt-train.txt', mode='r', encoding='utf8')\n",
        "tgt_val = open('./data/tgt-val.txt', mode='r', encoding='utf8')\n",
        "tgt_test = open('./data/tgt-test.txt', mode='r', encoding='utf8')\n",
        "\n",
        "# tgt_train_token = open('./data/tgt-train-token.txt', mode='w+', encoding='utf8')\n",
        "# tgt_val_token = open('./data/tgt-val-token.txt', mode='w+', encoding='utf8')\n",
        "# tgt_test_token = open('./data/tgt-test-token.txt', mode='w+', encoding='utf8')\n",
        "\n",
        "tokenize_file('./data/tgt-train.txt', './data/tgt-train-token.txt')\n",
        "tokenize_file('./data/tgt-val.txt', './data/tgt-val-token.txt')\n",
        "tokenize_file('./data/tgt-test.txt', './data/tgt-test-token.txt')\n",
        "\n",
        "n = 0\n",
        "for line in tgt_train:\n",
        "    n+=1\n",
        "print('Số lượng câu trong tập huấn luyện đích là ', n)\n",
        "n = 0\n",
        "for line in tgt_val:\n",
        "    n+=1\n",
        "print('Số lượng câu trong tập thẩm định đích là ', n)\n",
        "n = 0\n",
        "for line in tgt_test:\n",
        "    n+=1\n",
        "print('Số lượng câu trong tập kiểm tra đích là ', n)\n",
        "print(\"Tokenize sucess\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0-trwM6xiFT",
        "outputId": "1adabc32-b713-42a0-ce0a-0731b82dc2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spm_encode --model=target.model --input ./data/tgt-train.txt --output ./data/tgt-train-token.txt\n",
            "spm_encode --model=target.model --input ./data/tgt-val.txt --output ./data/tgt-val-token.txt\n",
            "spm_encode --model=target.model --input ./data/tgt-test.txt --output ./data/tgt-test-token.txt\n",
            "Số lượng câu trong tập huấn luyện đích là  14038\n",
            "Số lượng câu trong tập thẩm định đích là  1754\n",
            "Số lượng câu trong tập kiểm tra đích là  1756\n",
            "Tokenize sucess\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# set up OpenNMT config"
      ],
      "metadata": {
        "id": "V3bMUstFyWb7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## you should manually set epoch you want to done , best in my opinion is 80000 epoch but for demonstration here , let it be 2000"
      ],
      "metadata": {
        "id": "5MghBFoe3Xed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RcPJbdg8bRs",
        "outputId": "0d7e07b2-f1c7-4ac3-951a-48fd5a9f842d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## best config (recommended)"
      ],
      "metadata": {
        "id": "ykoq8FVg4bms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# epoch_num = 80000\n",
        "# save_checkpoint_num = 10000\n",
        "# valid_step = 10000\n"
      ],
      "metadata": {
        "id": "_dY0ONQx3lI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## demonstration config (not recommended)"
      ],
      "metadata": {
        "id": "LpvfUNuz4g4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_num = 2000\n",
        "save_checkpoint_num = 1000\n",
        "valid_step = 1000"
      ],
      "metadata": {
        "id": "VQpuEW7X4fQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get current date and time\n",
        "current_time = datetime.now()\n",
        "\n",
        "# Format the timestamp to include year, month, date, hour, and minute\n",
        "timestamp = current_time.strftime(\"%Y-%m-%d-%H-%M\")\n",
        "\n",
        "model_path = \"models/run2/model\"\n",
        "save_data_path = \"models/run2/example\"\n",
        "delete_path = \"models/run2\"\n",
        "import shutil\n",
        "import os\n",
        "if os.path.exists(delete_path):\n",
        "    shutil.rmtree(delete_path)\n",
        "    os.makedirs(delete_path, exist_ok=True)\n",
        "# https://opennmt.net/OpenNMT-py/FAQ.html#how-do-i-train-the-transformer-model\n",
        "def write_train_no_bpe_config():\n",
        "    config = f\"\"\"# data-no-bpe.yaml\n",
        "\n",
        "    ## Where the samples will be written\n",
        "    save_data: {save_data_path}\n",
        "    ## Where the vocab(s) will be written\n",
        "    src_vocab: vocab/example.vocab.src\n",
        "    tgt_vocab: vocab/example.vocab.tgt\n",
        "    # Prevent overwriting existing files in the folder\n",
        "    overwrite: True\n",
        "\n",
        "    # Corpus opts:\n",
        "    data:\n",
        "        corpus_1:\n",
        "            path_src: data/src-train-token.txt\n",
        "            path_tgt: data/tgt-train-token.txt\n",
        "        valid:\n",
        "            path_src: data/src-val-token.txt\n",
        "            path_tgt: data/tgt-val-token.txt\n",
        "\n",
        "\n",
        "    # Where to save the checkpoints\n",
        "    save_model: {model_path}\n",
        "    save_checkpoint_steps: {save_checkpoint_num}\n",
        "    valid_steps: {valid_step}\n",
        "    train_steps: {epoch_num}\n",
        "\n",
        "    # Batching\n",
        "    bucket_size: 262144\n",
        "\n",
        "\n",
        "    num_workers: 4\n",
        "    batch_type: \"tokens\"\n",
        "    batch_size: 4096\n",
        "    valid_batch_size: 2048\n",
        "    accum_count: [4]\n",
        "    accum_steps: [0]\n",
        "\n",
        "    # Optimization\n",
        "    model_dtype: \"fp16\"\n",
        "    optim: \"adam\"\n",
        "    learning_rate: 2\n",
        "    warmup_steps: 8000\n",
        "    decay_method: \"noam\"\n",
        "    adam_beta2: 0.998\n",
        "    max_grad_norm: 0\n",
        "    label_smoothing: 0.1\n",
        "    param_init: 0\n",
        "    param_init_glorot: true\n",
        "    normalization: \"tokens\"\n",
        "\n",
        "\n",
        "    # Model\n",
        "    encoder_type: transformer\n",
        "    decoder_type: transformer\n",
        "    position_encoding: true\n",
        "    enc_layers: 6\n",
        "    dec_layers: 6\n",
        "    heads: 8\n",
        "    rnn_size: 512\n",
        "    word_vec_size: 512\n",
        "    transformer_ff: 2048\n",
        "    dropout_steps: [0]\n",
        "    dropout: [0.1]\n",
        "    attention_dropout: [0.1]\n",
        "\n",
        "\n",
        "    world_size: 1\n",
        "    gpu_ranks:\n",
        "    - 0\n",
        "    \"\"\"\n",
        "\n",
        "    with open(\"khmer-viet-no-bpe.yaml\", \"w\") as f:\n",
        "        f.write(config)\n",
        "\n",
        "\n",
        "def write_train_bpe_config():\n",
        "    config = f\"\"\"# khmer-viet.yaml\n",
        "\n",
        "    ## Where the samples will be written\n",
        "    save_data: {save_data_path}\n",
        "    ## Where the vocab(s) will be written\n",
        "    src_vocab: example.vocab.src\n",
        "    tgt_vocab: example.vocab.tgt\n",
        "    # Prevent overwriting existing files in the folder\n",
        "    overwrite: True\n",
        "\n",
        "    # Corpus opts:\n",
        "    data:\n",
        "        corpus_1:\n",
        "            path_src: data/src-train-bpe.txt\n",
        "            path_tgt: data/tgt-train-bpe.txt\n",
        "        valid:\n",
        "            path_src: data/src-val-bpe.txt\n",
        "            path_tgt: data/tgt-val-bpe.txt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Where to save the checkpoints\n",
        "    save_model: {model_path}\n",
        "    save_checkpoint_steps: {save_checkpoint_num}\n",
        "    valid_steps: {valid_step}\n",
        "    train_steps: {epoch_num}\n",
        "\n",
        "    # Batching\n",
        "    bucket_size: 262144\n",
        "\n",
        "\n",
        "    num_workers: 4\n",
        "    batch_type: \"tokens\"\n",
        "    batch_size: 4096\n",
        "    valid_batch_size: 2048\n",
        "    accum_count: [4]\n",
        "    accum_steps: [0]\n",
        "\n",
        "    # Optimization\n",
        "    model_dtype: \"fp16\"\n",
        "    optim: \"adam\"\n",
        "    learning_rate: 2\n",
        "    warmup_steps: 8000\n",
        "    decay_method: \"noam\"\n",
        "    adam_beta2: 0.998\n",
        "    max_grad_norm: 0\n",
        "    label_smoothing: 0.1\n",
        "    param_init: 0\n",
        "    param_init_glorot: true\n",
        "    normalization: \"tokens\"\n",
        "\n",
        "    # Model\n",
        "    encoder_type: transformer\n",
        "    decoder_type: transformer\n",
        "    position_encoding: true\n",
        "    enc_layers: 6\n",
        "    dec_layers: 6\n",
        "    heads: 8\n",
        "    rnn_size: 512\n",
        "    word_vec_size: 512\n",
        "    transformer_ff: 2048\n",
        "    dropout_steps: [0]\n",
        "    dropout: [0.1]\n",
        "    attention_dropout: [0.1]\n",
        "\n",
        "\n",
        "    world_size: 1\n",
        "    gpu_ranks:\n",
        "    - 0\n",
        "    \"\"\"\n",
        "    with open(\"khmer-viet.yaml\", \"w\") as f:\n",
        "        f.write(config)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    write_train_no_bpe_config()\n",
        "    write_train_bpe_config()\n",
        "    import os\n",
        "    import time\n",
        "    if not os.path.exists('output_log'):\n",
        "        os.makedirs('output_log', exist_ok=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "v8F-TdQGx9zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# build vocab"
      ],
      "metadata": {
        "id": "EmMYgiuqytBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt_build_vocab -config khmer-viet-no-bpe.yaml -n_sample 10000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-qAfTKZyZ-p",
        "outputId": "514b2f76-5dcb-4e4e-e309-e6586a57b18f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sentencepiece/build/OpenNMT-py/onmt/modules/sparse_activations.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/content/sentencepiece/build/OpenNMT-py/onmt/modules/sparse_activations.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "/content/sentencepiece/build/OpenNMT-py/onmt/modules/sparse_losses.py:12: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/content/sentencepiece/build/OpenNMT-py/onmt/modules/sparse_losses.py:36: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "/content/sentencepiece/build/OpenNMT-py/onmt/models/sru.py:396: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/content/sentencepiece/build/OpenNMT-py/onmt/models/sru.py:442: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2025-04-21 15:23:07,961 INFO] Counter vocab from 10000 samples.\n",
            "[2025-04-21 15:23:07,961 INFO] Build vocab on 10000 transformed examples/corpus.\n",
            "[2025-04-21 15:23:07,972 INFO] corpus_1's transforms: TransformPipe()\n",
            "[2025-04-21 15:23:08,260 INFO] Counters src:3724\n",
            "[2025-04-21 15:23:08,260 INFO] Counters tgt:7465\n",
            "[2025-04-21 15:23:08,260 WARNING] path vocab/example.vocab.src exists, may overwrite...\n",
            "[2025-04-21 15:23:08,326 WARNING] path vocab/example.vocab.tgt exists, may overwrite...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train OpenNMT"
      ],
      "metadata": {
        "id": "1nk0BApnyvKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt_train -config khmer-viet-no-bpe.yaml -verbose --tensorboard --tensorboard_log_dir output_tensorboard_log\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9adJ5i4nye9D",
        "outputId": "074a24fe-5c1d-40e9-a069-d0f7f4d5bb03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sentencepiece/build/OpenNMT-py/onmt/modules/sparse_activations.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/content/sentencepiece/build/OpenNMT-py/onmt/modules/sparse_activations.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "/content/sentencepiece/build/OpenNMT-py/onmt/modules/sparse_losses.py:12: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/content/sentencepiece/build/OpenNMT-py/onmt/modules/sparse_losses.py:36: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "/content/sentencepiece/build/OpenNMT-py/onmt/models/sru.py:396: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/content/sentencepiece/build/OpenNMT-py/onmt/models/sru.py:442: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "[2025-04-21 15:23:12,863 INFO] Missing transforms field for corpus_1 data, set to default: [].\n",
            "[2025-04-21 15:23:12,863 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2025-04-21 15:23:12,863 INFO] Missing transforms field for valid data, set to default: [].\n",
            "[2025-04-21 15:23:12,863 INFO] Parsed 2 corpora from -data.\n",
            "[2025-04-21 15:23:12,863 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.\n",
            "[2025-04-21 15:23:12,863 INFO] Loading vocab from text file...\n",
            "[2025-04-21 15:23:12,863 INFO] Loading src vocabulary from vocab/example.vocab.src\n",
            "[2025-04-21 15:23:12,925 INFO] Loaded src vocab has 3724 tokens.\n",
            "[2025-04-21 15:23:12,927 INFO] Loading tgt vocabulary from vocab/example.vocab.tgt\n",
            "[2025-04-21 15:23:12,937 INFO] Loaded tgt vocab has 7465 tokens.\n",
            "[2025-04-21 15:23:12,940 INFO] Building fields with vocab in counters...\n",
            "[2025-04-21 15:23:12,947 INFO]  * tgt vocab size: 7469.\n",
            "[2025-04-21 15:23:12,950 INFO]  * src vocab size: 3726.\n",
            "[2025-04-21 15:23:12,950 INFO]  * src vocab size = 3726\n",
            "[2025-04-21 15:23:12,950 INFO]  * tgt vocab size = 7469\n",
            "[2025-04-21 15:23:12,966 INFO] Building model...\n",
            "[2025-04-21 15:23:14,541 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(3726, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-5): 6 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(7469, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-5): 6 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=7469, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax(dim=-1)\n",
            "  )\n",
            ")\n",
            "[2025-04-21 15:23:14,544 INFO] encoder: 20823040\n",
            "[2025-04-21 15:23:14,544 INFO] decoder: 32880941\n",
            "[2025-04-21 15:23:14,544 INFO] * number of parameters: 53703981\n",
            "/content/sentencepiece/build/OpenNMT-py/onmt/utils/optimizers.py:284: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  optimizer._scaler = GradScaler()\n",
            "2025-04-21 15:23:16.150899: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745248996.169903   24006 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745248996.175253   24006 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-21 15:23:16.192674: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[2025-04-21 15:23:18,510 INFO] NumExpr defaulting to 2 threads.\n",
            "[2025-04-21 15:23:18,752 INFO] Starting training on GPU: [0]\n",
            "[2025-04-21 15:23:18,752 INFO] Start training loop and validate every 1000 steps...\n",
            "[2025-04-21 15:23:18,753 INFO] corpus_1's transforms: TransformPipe()\n",
            "[2025-04-21 15:23:18,753 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2025-04-21 15:23:19,324 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2025-04-21 15:23:19,617 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2025-04-21 15:23:20,304 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2025-04-21 15:23:20,596 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2025-04-21 15:23:21,438 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2025-04-21 15:23:21,731 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 7\n",
            "[2025-04-21 15:23:22,035 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 8\n",
            "[2025-04-21 15:23:23,020 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 9\n",
            "[2025-04-21 15:23:23,315 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 10\n",
            "[2025-04-21 15:23:23,614 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 11\n",
            "[2025-04-21 15:23:23,913 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 12\n",
            "[2025-04-21 15:23:25,109 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 13\n",
            "[2025-04-21 15:23:25,400 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 14\n",
            "[2025-04-21 15:23:25,855 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 15\n",
            "[2025-04-21 15:23:26,308 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 16\n",
            "[2025-04-21 15:23:26,741 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 17\n",
            "[2025-04-21 15:23:28,418 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 18\n",
            "[2025-04-21 15:23:28,709 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 19\n",
            "/content/sentencepiece/build/OpenNMT-py/onmt/trainer.py:430: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.optim.amp):\n",
            "[2025-04-21 15:24:04,747 INFO] Step 50/ 2000; acc:   2.97; ppl: 1913.51; xent: 7.56; lr: 0.00001; 15847/14252 tok/s;     46 sec;\n",
            "[2025-04-21 15:24:30,624 INFO] Step 100/ 2000; acc:   6.56; ppl: 995.11; xent: 6.90; lr: 0.00001; 28028/24664 tok/s;     72 sec;\n",
            "[2025-04-21 15:24:56,493 INFO] Step 150/ 2000; acc:   6.51; ppl: 686.44; xent: 6.53; lr: 0.00002; 28245/25154 tok/s;     98 sec;\n",
            "[2025-04-21 15:25:23,053 INFO] Step 200/ 2000; acc:   6.79; ppl: 455.46; xent: 6.12; lr: 0.00002; 27455/24585 tok/s;    124 sec;\n",
            "[2025-04-21 15:25:49,856 INFO] Step 250/ 2000; acc:  10.12; ppl: 288.48; xent: 5.66; lr: 0.00003; 27063/24163 tok/s;    151 sec;\n",
            "[2025-04-21 15:26:16,694 INFO] Step 300/ 2000; acc:  11.83; ppl: 199.21; xent: 5.29; lr: 0.00004; 27325/24036 tok/s;    178 sec;\n",
            "[2025-04-21 15:26:43,086 INFO] Step 350/ 2000; acc:  15.43; ppl: 153.46; xent: 5.03; lr: 0.00004; 27678/24260 tok/s;    204 sec;\n",
            "[2025-04-21 15:27:09,724 INFO] Step 400/ 2000; acc:  18.68; ppl: 124.88; xent: 4.83; lr: 0.00005; 27489/24296 tok/s;    231 sec;\n",
            "[2025-04-21 15:27:36,285 INFO] Step 450/ 2000; acc:  20.71; ppl: 100.91; xent: 4.61; lr: 0.00006; 27389/24070 tok/s;    258 sec;\n",
            "[2025-04-21 15:28:02,872 INFO] Step 500/ 2000; acc:  22.79; ppl: 82.71; xent: 4.42; lr: 0.00006; 27327/24553 tok/s;    284 sec;\n",
            "[2025-04-21 15:28:29,628 INFO] Step 550/ 2000; acc:  23.75; ppl: 72.16; xent: 4.28; lr: 0.00007; 27229/24349 tok/s;    311 sec;\n",
            "[2025-04-21 15:28:56,310 INFO] Step 600/ 2000; acc:  25.52; ppl: 61.25; xent: 4.12; lr: 0.00007; 27378/24270 tok/s;    338 sec;\n",
            "[2025-04-21 15:29:12,803 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 20\n",
            "[2025-04-21 15:29:13,099 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 21\n",
            "[2025-04-21 15:29:13,396 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 22\n",
            "[2025-04-21 15:29:16,172 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 23\n",
            "[2025-04-21 15:29:16,600 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 24\n",
            "[2025-04-21 15:29:17,048 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 25\n",
            "[2025-04-21 15:29:17,529 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 26\n",
            "[2025-04-21 15:29:17,880 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 27\n",
            "[2025-04-21 15:29:18,192 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 28\n",
            "[2025-04-21 15:29:18,500 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 29\n",
            "[2025-04-21 15:29:18,853 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 30\n",
            "[2025-04-21 15:29:19,155 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 31\n",
            "[2025-04-21 15:29:19,457 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 32\n",
            "[2025-04-21 15:29:22,578 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 33\n",
            "[2025-04-21 15:29:22,873 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 34\n",
            "[2025-04-21 15:29:23,183 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 35\n",
            "[2025-04-21 15:29:23,481 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 36\n",
            "[2025-04-21 15:29:23,767 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 37\n",
            "[2025-04-21 15:29:24,089 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 38\n",
            "[2025-04-21 15:29:44,164 INFO] Step 650/ 2000; acc:  26.62; ppl: 54.00; xent: 3.99; lr: 0.00008; 15239/13488 tok/s;    385 sec;\n",
            "[2025-04-21 15:30:11,160 INFO] Step 700/ 2000; acc:  27.55; ppl: 47.65; xent: 3.86; lr: 0.00009; 27093/23832 tok/s;    412 sec;\n",
            "[2025-04-21 15:30:37,975 INFO] Step 750/ 2000; acc:  28.63; ppl: 44.55; xent: 3.80; lr: 0.00009; 27104/24182 tok/s;    439 sec;\n",
            "[2025-04-21 15:31:04,565 INFO] Step 800/ 2000; acc:  29.01; ppl: 40.51; xent: 3.70; lr: 0.00010; 27431/24376 tok/s;    466 sec;\n",
            "[2025-04-21 15:31:31,424 INFO] Step 850/ 2000; acc:  29.78; ppl: 37.09; xent: 3.61; lr: 0.00011; 27136/24042 tok/s;    493 sec;\n",
            "[2025-04-21 15:31:58,207 INFO] Step 900/ 2000; acc:  30.73; ppl: 34.67; xent: 3.55; lr: 0.00011; 27118/24226 tok/s;    519 sec;\n",
            "[2025-04-21 15:32:24,989 INFO] Step 950/ 2000; acc:  31.91; ppl: 30.95; xent: 3.43; lr: 0.00012; 27364/24099 tok/s;    546 sec;\n",
            "[2025-04-21 15:32:51,492 INFO] Step 1000/ 2000; acc:  32.93; ppl: 29.14; xent: 3.37; lr: 0.00012; 27381/23859 tok/s;    573 sec;\n",
            "[2025-04-21 15:32:51,494 INFO] valid's transforms: TransformPipe()\n",
            "/content/sentencepiece/build/OpenNMT-py/onmt/trainer.py:355: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.optim.amp):\n",
            "[2025-04-21 15:32:53,675 INFO] Validation perplexity: 46.7596\n",
            "[2025-04-21 15:32:53,675 INFO] Validation accuracy: 33.7247\n",
            "[2025-04-21 15:32:53,710 INFO] Saving checkpoint models/run2/model_step_1000.pt\n",
            "[2025-04-21 15:33:25,932 INFO] Step 1050/ 2000; acc:  33.74; ppl: 27.01; xent: 3.30; lr: 0.00013; 21159/18996 tok/s;    607 sec;\n",
            "[2025-04-21 15:33:52,894 INFO] Step 1100/ 2000; acc:  34.73; ppl: 25.32; xent: 3.23; lr: 0.00014; 27161/23966 tok/s;    634 sec;\n",
            "[2025-04-21 15:34:20,060 INFO] Step 1150/ 2000; acc:  36.24; ppl: 22.51; xent: 3.11; lr: 0.00014; 26563/23797 tok/s;    661 sec;\n",
            "[2025-04-21 15:34:47,355 INFO] Step 1200/ 2000; acc:  37.30; ppl: 20.94; xent: 3.04; lr: 0.00015; 26869/24151 tok/s;    689 sec;\n",
            "[2025-04-21 15:35:13,991 INFO] Step 1250/ 2000; acc:  38.08; ppl: 20.03; xent: 3.00; lr: 0.00015; 27504/23788 tok/s;    715 sec;\n",
            "[2025-04-21 15:35:21,255 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 39\n",
            "[2025-04-21 15:35:23,885 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 40\n",
            "[2025-04-21 15:35:24,153 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 41\n",
            "[2025-04-21 15:35:24,406 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 42\n",
            "[2025-04-21 15:35:24,654 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 43\n",
            "[2025-04-21 15:35:24,905 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 44\n",
            "[2025-04-21 15:35:25,167 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 45\n",
            "[2025-04-21 15:35:25,413 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 46\n",
            "[2025-04-21 15:35:25,647 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 47\n",
            "[2025-04-21 15:35:25,874 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 48\n",
            "[2025-04-21 15:35:28,978 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 49\n",
            "[2025-04-21 15:35:29,225 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 50\n",
            "[2025-04-21 15:35:29,457 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 51\n",
            "[2025-04-21 15:35:29,827 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 52\n",
            "[2025-04-21 15:35:30,194 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 53\n",
            "[2025-04-21 15:35:30,571 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 54\n",
            "[2025-04-21 15:35:30,952 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 55\n",
            "[2025-04-21 15:35:31,415 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 56\n",
            "[2025-04-21 15:35:31,820 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 57\n",
            "[2025-04-21 15:36:05,429 INFO] Step 1300/ 2000; acc:  39.93; ppl: 17.48; xent: 2.86; lr: 0.00016; 14214/12673 tok/s;    767 sec;\n",
            "[2025-04-21 15:36:32,752 INFO] Step 1350/ 2000; acc:  41.08; ppl: 16.42; xent: 2.80; lr: 0.00017; 26709/23697 tok/s;    794 sec;\n",
            "[2025-04-21 15:36:59,532 INFO] Step 1400/ 2000; acc:  42.04; ppl: 15.46; xent: 2.74; lr: 0.00017; 27208/24321 tok/s;    821 sec;\n",
            "[2025-04-21 15:37:26,318 INFO] Step 1450/ 2000; acc:  42.43; ppl: 14.75; xent: 2.69; lr: 0.00018; 27308/24345 tok/s;    848 sec;\n",
            "[2025-04-21 15:37:53,309 INFO] Step 1500/ 2000; acc:  43.47; ppl: 13.93; xent: 2.63; lr: 0.00019; 26983/23982 tok/s;    875 sec;\n",
            "[2025-04-21 15:38:20,231 INFO] Step 1550/ 2000; acc:  44.42; ppl: 13.03; xent: 2.57; lr: 0.00019; 27062/24226 tok/s;    901 sec;\n",
            "[2025-04-21 15:38:47,020 INFO] Step 1600/ 2000; acc:  45.95; ppl: 11.82; xent: 2.47; lr: 0.00020; 27241/23992 tok/s;    928 sec;\n",
            "[2025-04-21 15:39:13,838 INFO] Step 1650/ 2000; acc:  46.58; ppl: 11.50; xent: 2.44; lr: 0.00020; 27239/23960 tok/s;    955 sec;\n",
            "[2025-04-21 15:39:40,737 INFO] Step 1700/ 2000; acc:  47.21; ppl: 11.07; xent: 2.40; lr: 0.00021; 27254/24103 tok/s;    982 sec;\n",
            "[2025-04-21 15:40:07,543 INFO] Step 1750/ 2000; acc:  48.51; ppl: 10.07; xent: 2.31; lr: 0.00022; 27259/24154 tok/s;   1009 sec;\n",
            "[2025-04-21 15:40:34,362 INFO] Step 1800/ 2000; acc:  49.91; ppl:  9.52; xent: 2.25; lr: 0.00022; 27029/23900 tok/s;   1036 sec;\n",
            "[2025-04-21 15:41:01,291 INFO] Step 1850/ 2000; acc:  49.90; ppl:  9.26; xent: 2.23; lr: 0.00023; 27199/23884 tok/s;   1063 sec;\n",
            "[2025-04-21 15:41:25,798 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 58\n",
            "[2025-04-21 15:41:26,052 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 59\n",
            "[2025-04-21 15:41:26,314 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 60\n",
            "[2025-04-21 15:41:26,568 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 61\n",
            "[2025-04-21 15:41:26,815 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 62\n",
            "[2025-04-21 15:41:27,071 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 63\n",
            "[2025-04-21 15:41:27,340 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 64\n",
            "[2025-04-21 15:41:27,588 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 65\n",
            "[2025-04-21 15:41:27,827 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 66\n",
            "[2025-04-21 15:41:28,065 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 67\n",
            "[2025-04-21 15:41:31,679 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 68\n",
            "[2025-04-21 15:41:32,043 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 69\n",
            "[2025-04-21 15:41:32,418 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 70\n",
            "[2025-04-21 15:41:32,807 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 71\n",
            "[2025-04-21 15:41:33,184 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 72\n",
            "[2025-04-21 15:41:33,411 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 73\n",
            "[2025-04-21 15:41:33,653 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 74\n",
            "[2025-04-21 15:41:33,951 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 75\n",
            "[2025-04-21 15:41:51,136 INFO] Step 1900/ 2000; acc:  52.09; ppl:  8.33; xent: 2.12; lr: 0.00023; 14634/13012 tok/s;   1112 sec;\n",
            "[2025-04-21 15:42:18,188 INFO] Step 1950/ 2000; acc:  54.21; ppl:  7.30; xent: 1.99; lr: 0.00024; 26949/24122 tok/s;   1139 sec;\n",
            "[2025-04-21 15:42:45,133 INFO] Step 2000/ 2000; acc:  54.47; ppl:  7.34; xent: 1.99; lr: 0.00025; 26883/23729 tok/s;   1166 sec;\n",
            "[2025-04-21 15:42:47,024 INFO] Validation perplexity: 12.9974\n",
            "[2025-04-21 15:42:47,025 INFO] Validation accuracy: 50.9071\n",
            "[2025-04-21 15:42:47,045 INFO] Saving checkpoint models/run2/model_step_2000.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# checkpoint will be saved in /models/run2"
      ],
      "metadata": {
        "id": "Lm-hLyDry_ys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# time to inference (a.k.a translate)"
      ],
      "metadata": {
        "id": "GKEIgDdVzDoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## to translate new source text, you must first tokenize source text then put it through trained model then we obtain tokenize target text, then we detokenize target text. Done . Great job , buddy"
      ],
      "metadata": {
        "id": "22EP-Hy20Vib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ok let me give you this source file to translate"
      ],
      "metadata": {
        "id": "lnT1i8u706Yb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# there is a torch bug , you need to copy this below code replace code in file  OpenNMT-py/onmt/model_builder.py (i have comment the below code , but you need to put it in OpenNMT-py/onmt/model_builder.py to replace that file old code, then uncomment all new code)"
      ],
      "metadata": {
        "id": "hQtwCL9sFVOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"\n",
        "# This file is for models creation, which consults options\n",
        "# and creates each encoder and decoder accordingly.\n",
        "# \"\"\"\n",
        "# import re\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from torch.nn.init import xavier_uniform_\n",
        "\n",
        "# import onmt.modules\n",
        "# from onmt.encoders import str2enc\n",
        "\n",
        "# from onmt.decoders import str2dec\n",
        "\n",
        "# from onmt.modules import Embeddings, CopyGenerator\n",
        "# from onmt.modules.util_class import Cast\n",
        "# from onmt.utils.misc import use_gpu\n",
        "# from onmt.utils.logging import logger\n",
        "# from onmt.utils.parse import ArgumentParser\n",
        "# from onmt.constants import ModelTask\n",
        "\n",
        "\n",
        "# def build_embeddings(opt, text_field, for_encoder=True):\n",
        "#     \"\"\"\n",
        "#     Args:\n",
        "#         opt: the option in current environment.\n",
        "#         text_field(TextMultiField): word and feats field.\n",
        "#         for_encoder(bool): build Embeddings for encoder or decoder?\n",
        "#     \"\"\"\n",
        "#     emb_dim = opt.src_word_vec_size if for_encoder else opt.tgt_word_vec_size\n",
        "\n",
        "#     pad_indices = [f.vocab.stoi[f.pad_token] for _, f in text_field]\n",
        "#     word_padding_idx, feat_pad_indices = pad_indices[0], pad_indices[1:]\n",
        "\n",
        "#     num_embs = [len(f.vocab) for _, f in text_field]\n",
        "#     num_word_embeddings, num_feat_embeddings = num_embs[0], num_embs[1:]\n",
        "\n",
        "#     freeze_word_vecs = opt.freeze_word_vecs_enc if for_encoder \\\n",
        "#         else opt.freeze_word_vecs_dec\n",
        "\n",
        "#     emb = Embeddings(\n",
        "#         word_vec_size=emb_dim,\n",
        "#         position_encoding=opt.position_encoding,\n",
        "#         feat_merge=opt.feat_merge,\n",
        "#         feat_vec_exponent=opt.feat_vec_exponent,\n",
        "#         feat_vec_size=opt.feat_vec_size,\n",
        "#         dropout=opt.dropout[0] if type(opt.dropout) is list else opt.dropout,\n",
        "#         word_padding_idx=word_padding_idx,\n",
        "#         feat_padding_idx=feat_pad_indices,\n",
        "#         word_vocab_size=num_word_embeddings,\n",
        "#         feat_vocab_sizes=num_feat_embeddings,\n",
        "#         sparse=opt.optim == \"sparseadam\",\n",
        "#         freeze_word_vecs=freeze_word_vecs\n",
        "#     )\n",
        "#     return emb\n",
        "\n",
        "\n",
        "# def build_encoder(opt, embeddings):\n",
        "#     \"\"\"\n",
        "#     Various encoder dispatcher function.\n",
        "#     Args:\n",
        "#         opt: the option in current environment.\n",
        "#         embeddings (Embeddings): vocab embeddings for this encoder.\n",
        "#     \"\"\"\n",
        "#     enc_type = opt.encoder_type if opt.model_type == \"text\" else opt.model_type\n",
        "#     return str2enc[enc_type].from_opt(opt, embeddings)\n",
        "\n",
        "\n",
        "# def build_decoder(opt, embeddings):\n",
        "#     \"\"\"\n",
        "#     Various decoder dispatcher function.\n",
        "#     Args:\n",
        "#         opt: the option in current environment.\n",
        "#         embeddings (Embeddings): vocab embeddings for this decoder.\n",
        "#     \"\"\"\n",
        "#     dec_type = \"ifrnn\" if opt.decoder_type == \"rnn\" and opt.input_feed \\\n",
        "#                else opt.decoder_type\n",
        "#     return str2dec[dec_type].from_opt(opt, embeddings)\n",
        "\n",
        "# def load_test_model(opt, model_path=None):\n",
        "#     import torch\n",
        "#     from onmt.inputters.text_dataset import TextMultiField\n",
        "\n",
        "#     # Add TextMultiField to the allowed safe globals\n",
        "#     torch.serialization.add_safe_globals([TextMultiField])\n",
        "\n",
        "#     if model_path is None:\n",
        "#         model_path = opt.models[0]\n",
        "#     checkpoint = torch.load(model_path,\n",
        "#                             map_location=lambda storage, loc: storage, weights_only=False)\n",
        "\n",
        "\n",
        "#     model_opt = ArgumentParser.ckpt_model_opts(checkpoint['opt'])\n",
        "#     ArgumentParser.update_model_opts(model_opt)\n",
        "#     ArgumentParser.validate_model_opts(model_opt)\n",
        "#     fields = checkpoint['vocab']\n",
        "\n",
        "#     # Avoid functionality on inference\n",
        "#     model_opt.update_vocab = False\n",
        "\n",
        "#     model = build_base_model(model_opt, fields, use_gpu(opt), checkpoint,\n",
        "#                              opt.gpu)\n",
        "#     if opt.fp32:\n",
        "#         model.float()\n",
        "#     elif opt.int8:\n",
        "#         if opt.gpu >= 0:\n",
        "#             raise ValueError(\n",
        "#                 \"Dynamic 8-bit quantization is not supported on GPU\")\n",
        "#         torch.quantization.quantize_dynamic(model, inplace=True)\n",
        "#     model.eval()\n",
        "#     model.generator.eval()\n",
        "#     return fields, model, model_opt\n",
        "\n",
        "\n",
        "# def build_src_emb(model_opt, fields):\n",
        "#     # Build embeddings.\n",
        "#     if model_opt.model_type == \"text\":\n",
        "#         src_field = fields[\"src\"]\n",
        "#         src_emb = build_embeddings(model_opt, src_field)\n",
        "#     else:\n",
        "#         src_emb = None\n",
        "#     return src_emb\n",
        "\n",
        "\n",
        "# def build_encoder_with_embeddings(model_opt, fields):\n",
        "#     # Build encoder.\n",
        "#     src_emb = build_src_emb(model_opt, fields)\n",
        "#     encoder = build_encoder(model_opt, src_emb)\n",
        "#     return encoder, src_emb\n",
        "\n",
        "\n",
        "# def build_decoder_with_embeddings(\n",
        "#     model_opt, fields, share_embeddings=False, src_emb=None\n",
        "# ):\n",
        "#     # Build embeddings.\n",
        "#     tgt_field = fields[\"tgt\"]\n",
        "#     tgt_emb = build_embeddings(model_opt, tgt_field, for_encoder=False)\n",
        "\n",
        "#     if share_embeddings:\n",
        "#         tgt_emb.word_lut.weight = src_emb.word_lut.weight\n",
        "\n",
        "#     # Build decoder.\n",
        "#     decoder = build_decoder(model_opt, tgt_emb)\n",
        "#     return decoder, tgt_emb\n",
        "\n",
        "\n",
        "# def build_task_specific_model(model_opt, fields):\n",
        "#     # Share the embedding matrix - preprocess with share_vocab required.\n",
        "#     if model_opt.share_embeddings:\n",
        "#         # src/tgt vocab should be the same if `-share_vocab` is specified.\n",
        "#         assert (\n",
        "#             fields[\"src\"].base_field.vocab == fields[\"tgt\"].base_field.vocab\n",
        "#         ), \"preprocess with -share_vocab if you use share_embeddings\"\n",
        "\n",
        "#     if model_opt.model_task == ModelTask.SEQ2SEQ:\n",
        "#         encoder, src_emb = build_encoder_with_embeddings(model_opt, fields)\n",
        "#         decoder, _ = build_decoder_with_embeddings(\n",
        "#             model_opt,\n",
        "#             fields,\n",
        "#             share_embeddings=model_opt.share_embeddings,\n",
        "#             src_emb=src_emb,\n",
        "#         )\n",
        "#         return onmt.models.NMTModel(encoder=encoder, decoder=decoder)\n",
        "#     elif model_opt.model_task == ModelTask.LANGUAGE_MODEL:\n",
        "#         src_emb = build_src_emb(model_opt, fields)\n",
        "#         decoder, _ = build_decoder_with_embeddings(\n",
        "#             model_opt, fields, share_embeddings=True, src_emb=src_emb\n",
        "#         )\n",
        "#         return onmt.models.LanguageModel(decoder=decoder)\n",
        "#     else:\n",
        "#         raise ValueError(f\"No model defined for {model_opt.model_task} task\")\n",
        "\n",
        "\n",
        "# def use_embeddings_from_checkpoint(fields, model, generator, checkpoint):\n",
        "#     # Update vocabulary embeddings with checkpoint embeddings\n",
        "#     logger.info(\"Updating vocabulary embeddings with checkpoint embeddings\")\n",
        "#     # Embedding layers\n",
        "#     enc_emb_name = \"encoder.embeddings.make_embedding.emb_luts.0.weight\"\n",
        "#     dec_emb_name = \"decoder.embeddings.make_embedding.emb_luts.0.weight\"\n",
        "\n",
        "#     for field_name, emb_name in [(\"src\", enc_emb_name), (\"tgt\", dec_emb_name)]:\n",
        "#         if emb_name not in checkpoint[\"model\"]:\n",
        "#             continue\n",
        "#         multifield = fields[field_name]\n",
        "#         checkpoint_multifield = checkpoint[\"vocab\"][field_name]\n",
        "#         for (name, field), (checkpoint_name, checkpoint_field) in zip(\n",
        "#             multifield, checkpoint_multifield\n",
        "#         ):\n",
        "#             new_tokens = []\n",
        "#             for i, tok in enumerate(field.vocab.itos):\n",
        "#                 if tok in checkpoint_field.vocab.stoi:\n",
        "#                     old_i = checkpoint_field.vocab.stoi[tok]\n",
        "#                     model.state_dict()[emb_name][i] = checkpoint[\"model\"][\n",
        "#                         emb_name\n",
        "#                     ][old_i]\n",
        "#                     if field_name == \"tgt\":\n",
        "#                         generator.state_dict()[\"0.weight\"][i] = checkpoint[\n",
        "#                             \"generator\"\n",
        "#                         ][\"0.weight\"][old_i]\n",
        "#                         generator.state_dict()[\"0.bias\"][i] = checkpoint[\n",
        "#                             \"generator\"\n",
        "#                         ][\"0.bias\"][old_i]\n",
        "#                 else:\n",
        "#                     # Just for debugging purposes\n",
        "#                     new_tokens.append(tok)\n",
        "#             logger.info(\"%s: %d new tokens\" % (name, len(new_tokens)))\n",
        "#         # Remove old vocabulary associated embeddings\n",
        "#         del checkpoint[\"model\"][emb_name]\n",
        "#     del checkpoint[\"generator\"][\"0.weight\"], checkpoint[\"generator\"][\"0.bias\"]\n",
        "\n",
        "\n",
        "# def build_base_model(model_opt, fields, gpu, checkpoint=None, gpu_id=None):\n",
        "#     \"\"\"Build a model from opts.\n",
        "\n",
        "#     Args:\n",
        "#         model_opt: the option loaded from checkpoint. It's important that\n",
        "#             the opts have been updated and validated. See\n",
        "#             :class:`onmt.utils.parse.ArgumentParser`.\n",
        "#         fields (dict[str, torchtext.data.Field]):\n",
        "#             `Field` objects for the model.\n",
        "#         gpu (bool): whether to use gpu.\n",
        "#         checkpoint: the model gnerated by train phase, or a resumed snapshot\n",
        "#                     model from a stopped training.\n",
        "#         gpu_id (int or NoneType): Which GPU to use.\n",
        "\n",
        "#     Returns:\n",
        "#         the NMTModel.\n",
        "#     \"\"\"\n",
        "\n",
        "#     # for back compat when attention_dropout was not defined\n",
        "#     try:\n",
        "#         model_opt.attention_dropout\n",
        "#     except AttributeError:\n",
        "#         model_opt.attention_dropout = model_opt.dropout\n",
        "\n",
        "#     # Build Model\n",
        "#     if gpu and gpu_id is not None:\n",
        "#         device = torch.device(\"cuda\", gpu_id)\n",
        "#     elif gpu and not gpu_id:\n",
        "#         device = torch.device(\"cuda\")\n",
        "#     elif not gpu:\n",
        "#         device = torch.device(\"cpu\")\n",
        "\n",
        "#     model = build_task_specific_model(model_opt, fields)\n",
        "\n",
        "#     # Build Generator.\n",
        "#     if not model_opt.copy_attn:\n",
        "#         if model_opt.generator_function == \"sparsemax\":\n",
        "#             gen_func = onmt.modules.sparse_activations.LogSparsemax(dim=-1)\n",
        "#         else:\n",
        "#             gen_func = nn.LogSoftmax(dim=-1)\n",
        "#         generator = nn.Sequential(\n",
        "#             nn.Linear(model_opt.dec_rnn_size,\n",
        "#                       len(fields[\"tgt\"].base_field.vocab)),\n",
        "#             Cast(torch.float32),\n",
        "#             gen_func\n",
        "#         )\n",
        "#         if model_opt.share_decoder_embeddings:\n",
        "#             generator[0].weight = model.decoder.embeddings.word_lut.weight\n",
        "#     else:\n",
        "#         tgt_base_field = fields[\"tgt\"].base_field\n",
        "#         vocab_size = len(tgt_base_field.vocab)\n",
        "#         pad_idx = tgt_base_field.vocab.stoi[tgt_base_field.pad_token]\n",
        "#         generator = CopyGenerator(model_opt.dec_rnn_size, vocab_size, pad_idx)\n",
        "#         if model_opt.share_decoder_embeddings:\n",
        "#             generator.linear.weight = model.decoder.embeddings.word_lut.weight\n",
        "\n",
        "#     # Load the model states from checkpoint or initialize them.\n",
        "#     if checkpoint is None or model_opt.update_vocab:\n",
        "#         if model_opt.param_init != 0.0:\n",
        "#             for p in model.parameters():\n",
        "#                 p.data.uniform_(-model_opt.param_init, model_opt.param_init)\n",
        "#             for p in generator.parameters():\n",
        "#                 p.data.uniform_(-model_opt.param_init, model_opt.param_init)\n",
        "#         if model_opt.param_init_glorot:\n",
        "#             for p in model.parameters():\n",
        "#                 if p.dim() > 1:\n",
        "#                     xavier_uniform_(p)\n",
        "#             for p in generator.parameters():\n",
        "#                 if p.dim() > 1:\n",
        "#                     xavier_uniform_(p)\n",
        "\n",
        "#         if hasattr(model, \"encoder\") and hasattr(model.encoder, \"embeddings\"):\n",
        "#             model.encoder.embeddings.load_pretrained_vectors(\n",
        "#                 model_opt.pre_word_vecs_enc)\n",
        "#         if hasattr(model.decoder, 'embeddings'):\n",
        "#             model.decoder.embeddings.load_pretrained_vectors(\n",
        "#                 model_opt.pre_word_vecs_dec)\n",
        "\n",
        "#     if checkpoint is not None:\n",
        "#         # This preserves backward-compat for models using customed layernorm\n",
        "#         def fix_key(s):\n",
        "#             s = re.sub(r'(.*)\\.layer_norm((_\\d+)?)\\.b_2',\n",
        "#                        r'\\1.layer_norm\\2.bias', s)\n",
        "#             s = re.sub(r'(.*)\\.layer_norm((_\\d+)?)\\.a_2',\n",
        "#                        r'\\1.layer_norm\\2.weight', s)\n",
        "#             return s\n",
        "\n",
        "#         checkpoint['model'] = {fix_key(k): v\n",
        "#                                for k, v in checkpoint['model'].items()}\n",
        "#         # end of patch for backward compatibility\n",
        "\n",
        "#         if model_opt.update_vocab:\n",
        "#             # Update model embeddings with those from the checkpoint\n",
        "#             # after initialization\n",
        "#             use_embeddings_from_checkpoint(fields, model, generator,\n",
        "#                                            checkpoint)\n",
        "\n",
        "#         model.load_state_dict(checkpoint['model'], strict=False)\n",
        "#         generator.load_state_dict(checkpoint['generator'], strict=False)\n",
        "\n",
        "#     model.generator = generator\n",
        "\n",
        "#     if model_opt.freeze_encoder:\n",
        "#         model.encoder.requires_grad_(False)\n",
        "#         model.encoder.embeddings.requires_grad_()\n",
        "\n",
        "#     if model_opt.freeze_decoder:\n",
        "#         model.decoder.requires_grad_(False)\n",
        "#         model.decoder.embeddings.requires_grad_()\n",
        "\n",
        "#     model.to(device)\n",
        "#     if model_opt.model_dtype == 'fp16' and model_opt.optim == 'fusedadam':\n",
        "#         model.half()\n",
        "#     return model\n",
        "\n",
        "\n",
        "# def build_model(model_opt, opt, fields, checkpoint):\n",
        "#     logger.info('Building model...')\n",
        "#     model = build_base_model(model_opt, fields, use_gpu(opt), checkpoint)\n",
        "#     logger.info(model)\n",
        "#     return model\n"
      ],
      "metadata": {
        "id": "9FEIsPw-FO-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "greVUVK4CE5U",
        "outputId": "75fb24fc-e68c-426a-fbe1-8aa0fdb5b528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Ñu lač kơ digơ̆, “Dlăng kơ kâo, leh anăn ngă msĕ mơh. Tơdah kâo truh kơ knhal kđông ngă tui si kâo ngă.\n",
        "Yêhôwa ăl kơ Y-Salômôn, kyuadah ai tiê ñu weh đuĕ leh mơ̆ng Yêhôwa Aê Diê phung Israel, pô bi êdah leh kơ ñu dua bliư̆,\n",
        "Ƀiădah tơdah mnơ̆ng bi knăl dơ̆ng đĭ ti dlông ƀuôn msĕ si kmeh săp pui, phung Benjamin wir dlăng kơ tluôn diñu; leh anăn nĕ anei, kluôm ƀuôn mâo săp pui đĭ phă adiê.\n",
        "Kyua klei ih ngêñ asei mlei kâo amâo dôk suaih ôh; leh anăn klang kâo ruă kyua klei soh kâo.\n",
        "Ngăn drăp adôk mơ̆ng dŏ plah mă phung bi blah mă leh mâo: năm êtuh kjuh pluh êma êbâo drei biăp ana,\n",
        "Aê Diê hơêč hmưi klei jăk jĭn kơ digơ̆ leh anăn lač kơ digơ̆, “Brei diih mâo anak leh anăn bi lar êngŭm, bi bŏ lăn ala, leh anăn brei diih jing khua kơ lăn ala; brei diih kiă kriê kan hlăm êa ksĭ, čĭm hlăm adiê, leh anăn jih jang mnơ̆ng hdĭp kpư̆ hiu ti lăn ala.”\n",
        "Anăn yơh jing ngăn dưn kơ phung Naptali tui si găp djuê diñu — ƀuôn prŏng mbĭt hŏng ƀuôn điêt diñu.\n",
        "Ƀiădah lu kŭmpăn srăng hriê mơ̆ng čar Kitim leh anăn srăng bi knap phung Asur leh anăn phung Êber; leh anăn wăt diñu mơh srăng rai.”\n",
        "“Hdơr bĕ ară anei, Ơ Yêhôwa, kâo kwưh kơ ih, klei kâo êbat leh ti anăp ih hŏng klei sĭt suôr leh anăn hŏng jih ai tiê, leh anăn ngă leh klei jăk ti anăp ală ih.” Leh anăn Y-Hêsêkia hia ênguôt snăk.\n",
        "Snăn bhiâo riâo rit Y-Sôl lĕ buh ti lăn jih asei mlei ñu, bŏ hŏng klei huĭ kyua klei Y-Samuel blŭ anăn; leh anăn ñu luč jih klei ktang hlăm ñu, kyuadah ñu amâo tuôm huă ƀơ̆ng ôh jih hruê leh anăn mlam anăn.\n",
        "Ñu lač, “Mă bĕ.” Snăn gơ̆ yơr kngan leh anăn mă mta jông anăn.\n",
        "Hơ̆k mơak bĕ, Ơ phung găp djuê mnuih mbĭt hŏng phung ƀuôn sang ñu, kyuadah ñu srăng rŭ ênua êrah phung dĭng buăl ñu, leh anăn rŭ ênua kơ phung roh ñu, leh anăn ngă klei bhuah bi doh kơ ala čar ñu, kơ phung ƀuôn sang ñu.\n",
        "knưl čuh mnơ̆ng ƀâo mngưi wăt giê kkung ñu, êa ƀâo mngưi pioh trôč, leh anăn mnơ̆ng ƀâo mngưi; leh anăn čhiăm păng ti ƀăng bhă mŭt sang čhiăm;\n",
        "Ñu ngă klei djŏ ti anăp ală Yêhôwa, tui si jih klei Y-Đawit aê ñu ngă leh.\n",
        "Hmei phung khua ngă yang, phung Lêwi, leh anăn phung ƀuôn sang ngă leh klei mđăo, kơ klei myơr djuh, čiăng djă ba dŏ anăn hlăm sang Aê Diê hmei, tui si sang phung ama hmei ti hruê bi kčah leh, grăp thŭn, čiăng čuh ti dlông knưl Yêhôwa Aê Diê hmei tui si čih leh hlăm klei bhiăn.\n",
        "brei ñu yap thŭn mơ̆ng ñu čhĭ leh anăn lŏ tla tơl ênŭm ênoh mnuih anăn blei leh gơ̆, leh anăn ñu srăng lŏ wĭt kơ lăn ñu.\n",
        "“Si ngă Pô Mâo Jih Klei Myang amâo bi kčah ôh hruê phat kđi, leh anăn si ngă phung thâo kral ñu amâo ƀuh ôh hruê anăn truh?\n",
        "Phung anak čô Y-Pahat-Môap, čiăng lač phung anak čô Y-Jêsua leh anăn Y-Jôap mâo dua êbâo sa păn êtuh pluh sa păn čô.\n",
        "Tơdah khua ñu brei mô̆ kơ ñu leh anăn mô̆ ñu kkiêng kơ anak êkei amâodah mniê, mô̆ leh anăn phung anak gơ̆ srăng jing dŏ khua ñu, leh anăn ñu srăng kbiă hjăn ñu.\n",
        "Tui si Yêhôwa mtă leh kơ Y-Môis dĭng buăl Ñu, snăn Y-Môis mtă kơ Y-Yôsuê, leh anăn Y-Yôsuê ngă snăn. Ñu amâo kƀah ôh ngă sa mta mơ̆ng jih jang klei Yêhôwa mtă leh kơ Y-Môis.\n",
        "Tơdah diñu ayŭ ki ktang leh anăn sui, tơdah diih hmư̆ asăp ki, brei jih jang phung ƀuôn sang ur driâo kraih ktang; hlăk anăn mnư̆ ƀuôn anăn srăng klưh, leh anăn phung ƀuôn sang srăng đĭ grăp čô phă anăp ñu pô.”\n",
        "\"\"\"\n",
        "with open (\"testing_data.txt\", \"w\") as f:\n",
        "    f.write (text)"
      ],
      "metadata": {
        "id": "VTEIIgHx1DV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tokenize source file"
      ],
      "metadata": {
        "id": "cK-lPWk-13s7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZl60pGR2Cg8",
        "outputId": "910dbbf2-f71c-456a-d581-dca01e4ba3e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess"
      ],
      "metadata": {
        "id": "Yb1VCJSTCJrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_checkpoint_tokenizer_path = \"source.model\"\n",
        "filepath = \"testing_data.txt\"\n",
        "tokenized_for_infer_file = \"testing_data_tokenized.txt\"\n",
        "\n",
        "command = [\"spm_encode\",\n",
        "            f\"--model={source_checkpoint_tokenizer_path}\",\n",
        "            \"--input\", filepath,\n",
        "            \"--output\", tokenized_for_infer_file]\n",
        "print (\" \".join(command))\n",
        "# Running the subprocess with the provided command\n",
        "result = subprocess.run(command, capture_output=True, text=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V88Ceo1RyjZx",
        "outputId": "e1bee850-636a-4ccf-bef5-4bbdb54ebab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spm_encode --model=source.model --input testing_data.txt --output testing_data_tokenized.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## translate"
      ],
      "metadata": {
        "id": "30Aje_a016D7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_file(model_path, src_path, output_path):\n",
        "    command = [\"onmt_translate\",\n",
        "            \"--model\", model_path,\n",
        "            \"--src\", src_path,\n",
        "            \"--output\", output_path,\n",
        "            \"--verbose\",\n",
        "            \"--gpu\", \"0\"]\n",
        "    print (\"start process ....\")\n",
        "    print (\"running command\", \" \".join(command))\n",
        "    process = subprocess.run(command,\n",
        "            capture_output=True,\n",
        "            shell=False,\n",
        "            text=True,\n",
        "            encoding = 'utf-8')\n",
        "    # Checking if the process was successful\n",
        "\n",
        "    if process.returncode == 0:\n",
        "        # Process stdout (translation output)\n",
        "        print(process.stdout)\n",
        "    else:\n",
        "        # If there was an error, print stderr\n",
        "        print(\"Error:\", process.stderr)\n",
        "    print (\"end process ....\")\n"
      ],
      "metadata": {
        "id": "n3VImYAo185z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_checkpoint_path = \"models/run2/model_step_80000.pt\"\n",
        "model_checkpoint_path = \"models/run2/model_step_2000.pt\"\n",
        "tokenized_file = \"testing_data_tokenized.txt\"\n",
        "output_filepath = \"testing_data_translated.txt\"\n",
        "translate_file(\n",
        "    model_path=model_checkpoint_path,\n",
        "    src_path=tokenized_file,\n",
        "    output_path=output_filepath)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "408JmwBj2FHt",
        "outputId": "ad01272b-9253-44b7-d8af-0947213cae16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start process ....\n",
            "running command onmt_translate --model models/run2/model_step_2000.pt --src testing_data_tokenized.txt --output testing_data_translated.txt --verbose --gpu 0\n",
            "\n",
            "end process ....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## detokenize output file (using trained target.model tokenizer)"
      ],
      "metadata": {
        "id": "F0pKwX-42Sqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detokenize_file(src_path, file_to_translate, target_checkpoint_tokenizer_path):\n",
        "    en_output = []\n",
        "    with open (file_to_translate, 'r') as f:\n",
        "        need_translate_lines = f.readlines()\n",
        "\n",
        "    import subprocess\n",
        "    model_path = target_checkpoint_tokenizer_path\n",
        "    input = src_path\n",
        "    intermediate_output = src_path.replace(\".txt\", \"_detokenized.txt\")\n",
        "    command = f\"spm_decode --model={model_path} --input_format=piece < {input} > {intermediate_output}\"\n",
        "    print (command)\n",
        "    # Running the subprocess with the provided command\n",
        "    subprocess.run(command, shell=True, check=True)\n",
        "    time.sleep(10)\n"
      ],
      "metadata": {
        "id": "eZ_cZO7r2flc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_checkpoint_tokenizer_path = \"target.model\"\n",
        "refined_file_to_translate = \"testing_data.txt\"\n",
        "detokenize_file(src_path=output_filepath,\n",
        "                file_to_translate = refined_file_to_translate,\n",
        "                target_checkpoint_tokenizer_path = target_checkpoint_tokenizer_path\n",
        "                )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ecxo6mqv2RzF",
        "outputId": "4a026a1d-9dd0-4aa4-ca8b-f0fded86d685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spm_decode --model=target.model --input_format=piece < testing_data_translated.txt > testing_data_translated_detokenized.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Done. The final result is in testing_data_translated_detokenized.txt"
      ],
      "metadata": {
        "id": "S3usitVnF9eO"
      }
    }
  ]
}